{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEaZTyyE2MUv",
        "outputId": "f9cab1ca-8838-4954-b5f2-3072e5e19f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "pip install deap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/anyoptimization/pymoo\n",
        "!cd pymoo && pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg7qtDem2VAC",
        "outputId": "1538c235-a339-4d95-8e75-d45c8c83653d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pymoo'...\n",
            "remote: Enumerating objects: 12335, done.\u001b[K\n",
            "remote: Counting objects: 100% (2890/2890), done.\u001b[K\n",
            "remote: Compressing objects: 100% (930/930), done.\u001b[K\n",
            "remote: Total 12335 (delta 2184), reused 2310 (delta 1950), pack-reused 9445 (from 1)\u001b[K\n",
            "Receiving objects: 100% (12335/12335), 18.37 MiB | 16.65 MiB/s, done.\n",
            "Resolving deltas: 100% (7760/7760), done.\n",
            "Processing /content/pymoo\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from pymoo==0.6.1.3) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pymoo==0.6.1.3) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from pymoo==0.6.1.3) (3.8.0)\n",
            "Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.10/dist-packages (from pymoo==0.6.1.3) (1.7.0)\n",
            "Collecting cma>=3.2.2 (from pymoo==0.6.1.3)\n",
            "  Downloading cma-4.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting alive-progress (from pymoo==0.6.1.3)\n",
            "  Downloading alive_progress-3.2.0-py3-none-any.whl.metadata (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from pymoo==0.6.1.3)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pymoo==0.6.1.3) (1.2.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.6.1.3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.6.1.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.6.1.3) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.6.1.3) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.6.1.3) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.6.1.3) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.6.1.3) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.6.1.3) (2.8.2)\n",
            "Collecting about-time==4.2.1 (from alive-progress->pymoo==0.6.1.3)\n",
            "  Downloading about_time-4.2.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting grapheme==0.6.0 (from alive-progress->pymoo==0.6.1.3)\n",
            "  Downloading grapheme-0.6.0.tar.gz (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->pymoo==0.6.1.3) (1.17.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo==0.6.1.3) (1.16.0)\n",
            "Downloading cma-4.0.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.5/283.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alive_progress-3.2.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading about_time-4.2.1-py3-none-any.whl (13 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pymoo, grapheme\n",
            "  Building wheel for pymoo (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymoo: filename=pymoo-0.6.1.3-cp310-cp310-linux_x86_64.whl size=3693592 sha256=88d0d0221cdbe51224854b4f7ffbf3bc48a297565f5576c1525f8da3291f7e1f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f1prlw_6/wheels/2a/04/15/85f4edd051737e923a39821893d54514f5017b6c265355981a\n",
            "  Building wheel for grapheme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grapheme: filename=grapheme-0.6.0-py3-none-any.whl size=210082 sha256=6ee8ba4fea086d51e8ef07a9c88c2e789acb6e2d15a09e4d54ac2ca08059f801\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/e1/49/37e6bde9886439057450c494a79b0bef8bbe897a54aebfc757\n",
            "Successfully built pymoo grapheme\n",
            "Installing collected packages: grapheme, dill, cma, about-time, alive-progress, pymoo\n",
            "Successfully installed about-time-4.2.1 alive-progress-3.2.0 cma-4.0.0 dill-0.3.9 grapheme-0.6.0 pymoo-0.6.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import numpy\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as cm\n",
        "import matplotlib.pyplot as plt\n",
        "from deap import benchmarks\n",
        "import numpy as np\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.core.problem import Problem\n",
        "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
        "from pymoo.core.sampling import Sampling\n",
        "from pymoo.operators.crossover.sbx import SimulatedBinaryCrossover\n",
        "from pymoo.core.individual import Individual\n",
        "\n",
        "from pymoo.core.crossover import Crossover\n",
        "from pymoo.core.variable import Real, get\n",
        "from pymoo.operators.repair.bounds_repair import repair_clamp"
      ],
      "metadata": {
        "id": "86py9LPq2XXc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dynamic_xu_xl(model_keys) :\n",
        "    assert len(model_keys) == 4\n",
        "    xu = []\n",
        "    xl = []\n",
        "    for model_key in model_keys:\n",
        "        match model_key:\n",
        "            case 0:\n",
        "                xl.extend([2, 0])\n",
        "                xu.extend([16, 0])\n",
        "            case 1:\n",
        "                xl.extend([4, 1])\n",
        "                xu.extend([8, 8])\n",
        "            case 2:\n",
        "                xl.extend([1, 0])\n",
        "                xu.extend([28, 0])\n",
        "            case 3:\n",
        "                xl.extend([2, 2])\n",
        "                xu.extend([6, 3])\n",
        "            case 4:\n",
        "                xl.extend([4, 0])\n",
        "                xu.extend([16, 0])\n",
        "            case 5:\n",
        "                xl.extend([4, 1])\n",
        "                xu.extend([8, 8])\n",
        "            case 6:\n",
        "                xl.extend([1, 1])\n",
        "                xu.extend([3, 4])\n",
        "            case 7:\n",
        "                xl.extend([2, 2])\n",
        "                xu.extend([16, 16])\n",
        "            case 8:\n",
        "                xl.extend([4, 0])\n",
        "                xu.extend([8, 0])\n",
        "\n",
        "    return np.array(xl), np.array(xu)\n"
      ],
      "metadata": {
        "id": "bF-0749h2YsA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomIntegerRandomSampling(Sampling):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def _do(self, problem, n_samples, **kwargs):\n",
        "        n = int(problem.n_var / 3)\n",
        "        xl, xu = problem.bounds()\n",
        "        xl = xl[0:n]\n",
        "        xu = xu[0:n]\n",
        "        X = np.column_stack([np.random.randint(xl[k], xu[k] + 1, size=n_samples) for k in range(n)])\n",
        "        full_solution = np.zeros((n_samples, problem.n_var))\n",
        "        full_solution[:, :n] = X\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            Dxl, Dxu = dynamic_xu_xl(X[i])\n",
        "            dynamic_params = np.array([np.random.randint(Dxl[k], Dxu[k] + 1) for k in range(2*n)])\n",
        "            full_solution[i, n:] = dynamic_params\n",
        "\n",
        "        # Convert full_solution to array of Individuals using frompyfunc\n",
        "        individuals = np.array([Individual(X=x) for x in full_solution])\n",
        "        return individuals"
      ],
      "metadata": {
        "id": "wMXC1qaT2alf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymoo.core.crossover import Crossover\n",
        "from pymoo.util.misc import crossover_mask\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class UniformCrossoverv(Crossover):\n",
        "\n",
        "    def __init__(self,\n",
        "                 prob_var=1.0,\n",
        "                 eta=15,\n",
        "                 prob_exch=1.0,\n",
        "                 prob_bin=0.5,\n",
        "                 n_offsprings=1,\n",
        "                 **kwargs):\n",
        "        super().__init__(2, 1, **kwargs)\n",
        "        self.prob_var = Real(prob_var, bounds=(0.1, 0.9))\n",
        "        self.eta = Real(eta, bounds=(3.0, 30.0), strict=(1.0, None))\n",
        "        self.prob_exch = Real(prob_exch, bounds=(0.0, 1.0), strict=(0.0, 1.0))\n",
        "        self.prob_bin = Real(prob_bin, bounds=(0.0, 1.0), strict=(0.0, 1.0))\n",
        "\n",
        "    def _do(self, _, X, **kwargs):\n",
        "        _, n_matings, n_var = X.shape\n",
        "        n_var /= 3\n",
        "        n_var = int(n_var)\n",
        "        X_model_conf = X[:, :, :4]\n",
        "        X_model_params = X[:, :, 4:]\n",
        "        M = np.random.random((n_matings, n_var)) < 0.5\n",
        "        _X_model_conf = crossover_mask(X_model_conf, M)\n",
        "        xl_mat, xu_mat = np.empty((0, n_var * 2)), np.empty((0, n_var * 2))\n",
        "        if self.n_offsprings == 1:\n",
        "            rand = np.random.random(size=n_matings) < 0.5\n",
        "            _X_model_conf[0, rand] = _X_model_conf[1, rand]\n",
        "            _X_model_conf = _X_model_conf[[0]]\n",
        "        for t in _X_model_conf :\n",
        "            for conf in t:\n",
        "                dynamic_xl, dynamic_xu = dynamic_xu_xl(conf)\n",
        "                xl_mat = np.vstack([xl_mat, dynamic_xl])\n",
        "                xu_mat = np.vstack([xu_mat, dynamic_xu])\n",
        "\n",
        "\n",
        "        _, n_matings, _ = X_model_params.shape\n",
        "        n_var *= 3\n",
        "        # get the parameters required by SBX\n",
        "        eta, prob_var, prob_exch, prob_bin = get(self.eta, self.prob_var, self.prob_exch, self.prob_bin, size=(n_matings, 1))\n",
        "\n",
        "        # set the binomial probability to zero if no exchange between individuals shall happen\n",
        "        rand = np.random.random((len(prob_bin), 1))\n",
        "        prob_bin[rand > prob_exch] = 0.0\n",
        "        print(\"shape\")\n",
        "        print(xl_mat.shape)\n",
        "        Q = cross_sbx(X_model_params.astype(float), xl_mat, xu_mat, eta, prob_var, prob_bin)\n",
        "\n",
        "        if self.n_offsprings == 1:\n",
        "            rand = np.random.random(size=n_matings) < 0.5\n",
        "            Q[0, rand] = Q[1, rand]\n",
        "            Q = Q[[0]]\n",
        "\n",
        "        print(\"LOLL\")\n",
        "        print(_X_model_conf.shape, Q.shape)\n",
        "        return np.concatenate((_X_model_conf, Q), axis=-1)\n",
        "\n",
        "\n",
        "def cross_sbx(X, xl, xu, eta, prob_var, prob_bin, eps=1.0e-14):\n",
        "    n_parents, n_matings, n_var = X.shape\n",
        "\n",
        "    # the probability of a crossover for each of the variables\n",
        "    cross = np.random.random((n_matings, n_var)) < prob_var\n",
        "\n",
        "    # when solutions are too close -> do not apply sbx crossover\n",
        "    too_close = np.abs(X[0] - X[1]) <= eps\n",
        "\n",
        "    # disable if two individuals are already too close\n",
        "    cross[too_close] = False\n",
        "\n",
        "    # disable crossover when lower and upper bound are identical\n",
        "    # cross[:, xl == xu] = False\n",
        "\n",
        "    # assign y1 the smaller and y2 the larger value\n",
        "    y1 = np.min(X, axis=0)[cross]\n",
        "    y2 = np.max(X, axis=0)[cross]\n",
        "\n",
        "    # mask all the values that should be crossovered\n",
        "    print(\"xl\")\n",
        "    print(xl.shape, cross.shape)\n",
        "    _xl = xl[cross]\n",
        "    _xu = xu[cross]\n",
        "    eta = eta.repeat(n_var, axis=1)[cross]\n",
        "    prob_bin = prob_bin.repeat(n_var, axis=1)[cross]\n",
        "    print(np.repeat(xl[None, :], n_matings, axis=0))\n",
        "    # random values for each individual\n",
        "    rand = np.random.random(len(eta))\n",
        "\n",
        "    def calc_betaq(beta):\n",
        "        epsilon = 1e-8  # A small value to avoid division by zero\n",
        "        alpha = 2.0 - np.power(np.maximum(beta, epsilon), -(eta + 1.0))\n",
        "\n",
        "        mask, mask_not = (rand <= (1.0 / alpha)), (rand > (1.0 / alpha))\n",
        "\n",
        "        betaq = np.zeros(mask.shape)\n",
        "        betaq[mask] = np.power(np.maximum((rand * alpha), 0.0), (1.0 / (eta + 1.0)))[mask]\n",
        "        betaq[mask_not] = np.power((1.0 / (2.0 - rand * alpha)), (1.0 / (eta + 1.0)))[mask_not]\n",
        "\n",
        "        return betaq\n",
        "\n",
        "    # difference between all variables\n",
        "    delta = (y2 - y1)\n",
        "\n",
        "    beta = 1.0 + (2.0 * (y1 - _xl) / delta)\n",
        "    betaq = calc_betaq(beta)\n",
        "    c1 = 0.5 * ((y1 + y2) - betaq * delta)\n",
        "\n",
        "    beta = 1.0 + (2.0 * (_xu - y2) / delta)\n",
        "    betaq = calc_betaq(beta)\n",
        "    c2 = 0.5 * ((y1 + y2) + betaq * delta)\n",
        "\n",
        "    # with the given probability either assign the value from the first or second parent\n",
        "    b = np.random.random(len(prob_bin)) < prob_bin\n",
        "    tmp = np.copy(c1[b])\n",
        "    c1[b] = c2[b]\n",
        "    c2[b] = tmp\n",
        "\n",
        "    # first copy the unmodified parents\n",
        "    Q = np.copy(X)\n",
        "\n",
        "    # copy the positions where the crossover was done\n",
        "    Q[0, cross] = c1\n",
        "    Q[1, cross] = c2\n",
        "\n",
        "    Q[0] = repair_clamp(Q[0], xl, xu)\n",
        "    Q[1] = repair_clamp(Q[1], xl, xu)\n",
        "\n",
        "    return Q\n"
      ],
      "metadata": {
        "id": "3XDQbp472cJp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def repair_clamp(Xp, xl, xu):\n",
        "\n",
        "    I = np.where(Xp < xl)\n",
        "    c = np.sum(Xp < xl)\n",
        "    Xp[I] = xl[I]\n",
        "\n",
        "    I = np.where(Xp > xu)\n",
        "    c += np.sum(Xp > xu)\n",
        "    Xp[I] = xu[I]\n",
        "    print(\"lolcount\")\n",
        "    print(c)\n",
        "    print(Xp.shape)\n",
        "    return Xp"
      ],
      "metadata": {
        "id": "4i9gNOOM2dtE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cur\n",
        "n_var, n_matings = 12, 30\n",
        "\n",
        "problem = Problem(n_var=12, n_obj=2, xl=[0, 0, 0, 0, -2, -2, -2, -2, -2, -2, -2, -2], xu=[8, 8, 8, 8, -2, -2, -2, -2, -2, -2, -2, -2])\n",
        "\n",
        "sampler = CustomIntegerRandomSampling()\n",
        "pop1 = sampler._do(problem, 30)\n",
        "\n",
        "pop2 = sampler._do(problem, 30)\n",
        "\n",
        "parent = [[a, b] for a, b in zip(pop1, pop2)]\n",
        "\n",
        "off = UniformCrossoverv(prob=1.0, eta = 1).do(problem, parent)\n",
        "Xp = off.get(\"X\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEpL9e0l2gDC",
        "outputId": "a9b2e33d-5a51-4bae-c9ae-067ff43ea4f5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape\n",
            "(30, 8)\n",
            "xl\n",
            "(30, 8) (30, 8)\n",
            "[[[1. 0. 4. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 2. 0.]\n",
            "  [2. 2. 1. ... 2. 2. 2.]\n",
            "  ...\n",
            "  [4. 0. 1. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 1. 1.]\n",
            "  [1. 1. 4. ... 1. 1. 0.]]\n",
            "\n",
            " [[1. 0. 4. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 2. 0.]\n",
            "  [2. 2. 1. ... 2. 2. 2.]\n",
            "  ...\n",
            "  [4. 0. 1. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 1. 1.]\n",
            "  [1. 1. 4. ... 1. 1. 0.]]\n",
            "\n",
            " [[1. 0. 4. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 2. 0.]\n",
            "  [2. 2. 1. ... 2. 2. 2.]\n",
            "  ...\n",
            "  [4. 0. 1. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 1. 1.]\n",
            "  [1. 1. 4. ... 1. 1. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1. 0. 4. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 2. 0.]\n",
            "  [2. 2. 1. ... 2. 2. 2.]\n",
            "  ...\n",
            "  [4. 0. 1. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 1. 1.]\n",
            "  [1. 1. 4. ... 1. 1. 0.]]\n",
            "\n",
            " [[1. 0. 4. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 2. 0.]\n",
            "  [2. 2. 1. ... 2. 2. 2.]\n",
            "  ...\n",
            "  [4. 0. 1. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 1. 1.]\n",
            "  [1. 1. 4. ... 1. 1. 0.]]\n",
            "\n",
            " [[1. 0. 4. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 2. 0.]\n",
            "  [2. 2. 1. ... 2. 2. 2.]\n",
            "  ...\n",
            "  [4. 0. 1. ... 2. 4. 1.]\n",
            "  [2. 0. 4. ... 0. 1. 1.]\n",
            "  [1. 1. 4. ... 1. 1. 0.]]]\n",
            "lolcount\n",
            "74\n",
            "(30, 8)\n",
            "lolcount\n",
            "85\n",
            "(30, 8)\n",
            "LOLL\n",
            "(1, 30, 4) (1, 30, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fR1hoMY2iVN",
        "outputId": "1259a838-d8b1-4fb1-8a60-65884ea86afa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.          4.          3.          1.          3.79919901  0.\n",
            "  12.68863739  0.          4.7348504   2.          8.          5.01499929]\n",
            " [ 0.          4.          0.          0.          5.67020546  0.\n",
            "  13.60636642  0.          4.02412304  0.         14.22201762  0.        ]\n",
            " [ 7.          6.          7.          3.          6.         11.25643161\n",
            "   3.          2.627287   13.95105034  5.57701803  2.          2.        ]\n",
            " [ 2.          3.          1.          7.          6.17093668  0.\n",
            "   6.          2.72443982  4.73780581  2.46676279  3.0219569   8.45976527]\n",
            " [ 0.          1.          6.          5.          2.          0.\n",
            "   8.          7.6172538   3.          1.          4.00287844  2.41352382]\n",
            " [ 6.          4.          1.          5.          3.          1.20803309\n",
            "   5.06086057  0.          7.80683995  1.9367039   8.          7.96096312]\n",
            " [ 4.          4.          2.          0.          4.          0.\n",
            "   7.60947118  0.         24.96991392  0.          4.29668868  0.        ]\n",
            " [ 7.          5.          0.          8.          2.05075834  2.40667214\n",
            "   8.          7.74552437  4.97115089  0.          4.          0.        ]\n",
            " [ 8.          4.          4.          6.          6.34302456  0.\n",
            "   4.          0.         15.9459097   0.          3.          2.30991059]\n",
            " [ 4.          6.          7.          2.         16.          0.\n",
            "   3.          1.93477489  6.60437813 11.35834739  6.          0.        ]\n",
            " [ 0.          8.          1.          3.         13.80986636  0.\n",
            "   7.37259047  0.          6.95636081  2.87084489  6.          2.        ]\n",
            " [ 0.          6.          2.          3.          5.02009604  0.\n",
            "   3.          2.00495507 13.          0.          2.52003144  2.46515532]\n",
            " [ 1.          2.          8.          2.          8.          5.61118296\n",
            "   2.5390335   0.          5.4768823   0.         11.20400414  0.        ]\n",
            " [ 0.          0.          6.          0.          7.73501496  0.\n",
            "   4.94147495  0.          3.          2.8442944  11.98341304  0.        ]\n",
            " [ 8.          7.          1.          3.          8.          0.\n",
            "   8.10461501 13.81679814  4.          3.88354019  6.          2.        ]\n",
            " [ 7.          4.          4.          8.         10.01764356 10.09197736\n",
            "   5.8843045   0.          8.87468326  0.          5.39689716  0.        ]\n",
            " [ 4.          3.          6.          5.          9.20749655  0.\n",
            "   4.69657367  2.97705846  3.          4.          4.          4.25183898]\n",
            " [ 0.          7.          4.          2.         15.91186032  0.\n",
            "   3.57532921  2.          6.          0.          1.21191139  0.        ]\n",
            " [ 4.          2.          0.          8.          4.          0.\n",
            "   1.11821875  0.          9.04283601  0.          6.66905533  0.        ]\n",
            " [ 6.          1.          8.          3.          3.          3.82279183\n",
            "   4.          5.29778275  8.          0.          6.          2.96760284]\n",
            " [ 5.          0.          4.          7.          4.          7.68457207\n",
            "   5.85715052  0.          4.          0.          5.85565343  2.02475452]\n",
            " [ 6.          3.          1.          2.          2.32516047  1.\n",
            "   5.15360929  2.01992008  6.4422406   1.95776028  3.80620754  0.        ]\n",
            " [ 2.          7.          3.          1.          6.15812179  0.\n",
            "  13.17544976  2.          5.40445636  2.          5.49639645  3.89777719]\n",
            " [ 2.          4.          5.          6.         17.73855001  0.\n",
            "   7.72195708  0.          4.97670624  1.          3.          1.85184948]\n",
            " [ 4.          0.          6.          0.          7.90076973  0.\n",
            "  13.71293946  0.          2.70781638  1.          6.50394191  0.        ]\n",
            " [ 5.          2.          7.          8.          4.44550022  6.42154146\n",
            "  10.05667468  0.         14.55661142 13.16789022  8.          0.        ]\n",
            " [ 3.          7.          6.          8.          6.          2.\n",
            "  14.17979508  2.          3.          1.          6.95509452  0.        ]\n",
            " [ 4.          2.          7.          1.         14.37526818  0.\n",
            "   5.85016065  0.         13.0024991   2.          8.          6.05584681]\n",
            " [ 0.          4.          2.          6.          2.          0.\n",
            "  11.25088944  0.         27.17509096  0.          3.          3.5074678 ]\n",
            " [ 6.          8.          5.          2.          3.          3.24435478\n",
            "   6.63252987  0.          7.85977478  2.47700127 24.94931114  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bitflip_mutation_dynamic(Xp, mutation_prob=0.1):\n",
        "    \"\"\"\n",
        "    Perform bitflip mutation on the offspring while adhering to dynamic bounds.\n",
        "\n",
        "    Parameters:\n",
        "    - Xp: np.array, the offspring population (n_offsprings, n_var).\n",
        "    - mutation_prob: float, probability of flipping each gene.\n",
        "\n",
        "    Returns:\n",
        "    - mutated_offsprings: np.array, mutated population of the same size as Xp.\n",
        "    \"\"\"\n",
        "    # Clone the offspring to mutate without altering the original\n",
        "    mutated_offsprings = Xp.copy()\n",
        "    n_offsprings, n_var = Xp.shape\n",
        "    n_model_keys = 4  # First 4 genes are model keys\n",
        "\n",
        "    # Iterate over each offspring\n",
        "    for i in range(n_offsprings):\n",
        "        # Mutate the model keys (first 4 genes)\n",
        "        for j in range(n_model_keys):\n",
        "            if np.random.random() < mutation_prob:\n",
        "                xl, xu = problem.xl[j], problem.xu[j]\n",
        "                mutated_offsprings[i, j] = np.random.randint(xl, xu + 1)\n",
        "\n",
        "        # Fetch the mutated model keys\n",
        "        model_keys = mutated_offsprings[i, :n_model_keys].astype(int)\n",
        "\n",
        "        # Get dynamic bounds for parameters\n",
        "        dynamic_xl, dynamic_xu = dynamic_xu_xl(model_keys)\n",
        "\n",
        "        # Mutate the parameters (remaining genes)\n",
        "        for j, (xl, xu) in enumerate(zip(dynamic_xl, dynamic_xu), start=n_model_keys):\n",
        "            if np.random.random() < mutation_prob:\n",
        "                mutated_offsprings[i, j] = np.random.randint(xl, xu + 1)\n",
        "\n",
        "    return mutated_offsprings\n",
        "\n",
        "\n",
        "# Mutation probability can be adjusted (e.g., 0.1 means 10% chance of flipping each gene)\n",
        "mutation_prob = 0.1\n",
        "\n",
        "# Apply bitflip mutation with dynamic bounds\n",
        "mutated_Xp = bitflip_mutation_dynamic(Xp, mutation_prob)\n",
        "\n",
        "# Print the mutated offsprings\n",
        "print(\"Mutated Offsprings:\")\n",
        "print(mutated_Xp)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuhdrYvS2jQU",
        "outputId": "9104d29d-3418-4439-ef1d-b5a66d250255"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutated Offsprings:\n",
            "[[ 2.          4.          3.          1.          3.79919901  0.\n",
            "  12.68863739  0.          4.7348504   2.          8.          5.01499929]\n",
            " [ 0.          4.          0.          0.         15.          0.\n",
            "  13.60636642  0.          8.          0.         14.22201762  0.        ]\n",
            " [ 7.          6.          7.          3.          6.         11.25643161\n",
            "   1.          2.627287   13.95105034  5.57701803  2.          2.        ]\n",
            " [ 2.          3.          3.          7.          6.17093668  0.\n",
            "   6.          3.          4.73780581  2.46676279  3.0219569   8.45976527]\n",
            " [ 0.          1.          6.          1.          2.          0.\n",
            "   8.          8.          3.          1.          4.00287844  2.41352382]\n",
            " [ 6.          4.          1.          5.          3.          1.20803309\n",
            "   5.06086057  0.          7.80683995  1.9367039   4.          7.96096312]\n",
            " [ 4.          4.          2.          0.          4.          0.\n",
            "   7.60947118  0.         24.96991392  0.          4.29668868  0.        ]\n",
            " [ 7.          5.          0.          8.          2.05075834  2.40667214\n",
            "   8.          7.74552437 12.          0.          4.          0.        ]\n",
            " [ 8.          4.          4.          6.          6.34302456  0.\n",
            "   4.          0.         15.9459097   0.          3.          2.30991059]\n",
            " [ 4.          6.          7.          2.         10.          0.\n",
            "   3.          3.          6.60437813 11.35834739 21.          0.        ]\n",
            " [ 0.          8.          1.          3.         13.80986636  0.\n",
            "   7.37259047  0.          5.          2.87084489  6.          2.        ]\n",
            " [ 0.          6.          2.          3.          5.02009604  0.\n",
            "   3.          2.00495507 13.          0.          2.          2.46515532]\n",
            " [ 1.          2.          5.          2.          8.          5.61118296\n",
            "   2.5390335   0.          5.4768823   0.         11.20400414  0.        ]\n",
            " [ 0.          0.          6.          0.          7.73501496  0.\n",
            "   5.          0.          3.          2.8442944  11.98341304  0.        ]\n",
            " [ 8.          7.          1.          3.          8.          0.\n",
            "   8.10461501 13.81679814  4.          1.          6.          2.        ]\n",
            " [ 7.          4.          4.          8.         10.01764356 10.09197736\n",
            "   5.8843045   0.          8.87468326  0.          5.39689716  0.        ]\n",
            " [ 0.          3.          6.          5.          9.20749655  0.\n",
            "   4.69657367  2.97705846  3.          4.          4.          4.25183898]\n",
            " [ 0.          7.          4.          2.         15.91186032  0.\n",
            "   3.57532921  2.          6.          0.         12.          0.        ]\n",
            " [ 4.          2.          0.          8.          4.          0.\n",
            "   1.11821875  0.          9.04283601  0.          6.66905533  0.        ]\n",
            " [ 6.          1.          3.          3.          3.          3.82279183\n",
            "   4.          5.29778275  2.          0.          6.          2.96760284]\n",
            " [ 3.          0.          4.          7.          4.          7.68457207\n",
            "   5.85715052  0.          4.          0.          5.85565343  2.02475452]\n",
            " [ 6.          3.          1.          2.          2.32516047  1.\n",
            "   5.15360929  2.01992008  6.4422406   1.95776028  3.80620754  0.        ]\n",
            " [ 2.          7.          3.          1.          6.15812179  0.\n",
            "  13.17544976  2.          5.40445636  2.          5.49639645  3.89777719]\n",
            " [ 2.          4.          5.          6.         17.73855001  0.\n",
            "   7.72195708  0.          4.97670624  1.          3.          4.        ]\n",
            " [ 4.          0.          6.          0.          7.90076973  0.\n",
            "  13.71293946  0.          2.70781638  1.          6.50394191  0.        ]\n",
            " [ 5.          2.          1.          7.          4.44550022  6.42154146\n",
            "  10.05667468  0.         14.55661142 13.16789022  8.          0.        ]\n",
            " [ 3.          7.          6.          8.          6.          2.\n",
            "  14.17979508  2.          3.          1.          6.95509452  0.        ]\n",
            " [ 4.          2.          7.          1.         14.37526818  0.\n",
            "   5.85016065  0.         13.0024991   2.          8.          6.05584681]\n",
            " [ 0.          4.          2.          6.          2.          0.\n",
            "   7.          0.         27.17509096  0.          3.          3.5074678 ]\n",
            " [ 6.          8.          5.          2.          3.          3.24435478\n",
            "   6.63252987  0.          7.85977478  2.47700127 24.94931114  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Round mutated offspring to the nearest integer\n",
        "mutated_Xp = [np.round(offspring).astype(int).tolist() for offspring in mutated_Xp]\n",
        "\n",
        "# Print the mutated offsprings\n",
        "print(\"Rounded Mutated Offsprings:\")\n",
        "print(mutated_Xp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72MtxB_76-EN",
        "outputId": "3513106b-d815-4991-9c13-36630d5e07cc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rounded Mutated Offsprings:\n",
            "[[2, 4, 3, 1, 4, 0, 13, 0, 5, 2, 8, 5], [0, 4, 0, 0, 15, 0, 14, 0, 8, 0, 14, 0], [7, 6, 7, 3, 6, 11, 1, 3, 14, 6, 2, 2], [2, 3, 3, 7, 6, 0, 6, 3, 5, 2, 3, 8], [0, 1, 6, 1, 2, 0, 8, 8, 3, 1, 4, 2], [6, 4, 1, 5, 3, 1, 5, 0, 8, 2, 4, 8], [4, 4, 2, 0, 4, 0, 8, 0, 25, 0, 4, 0], [7, 5, 0, 8, 2, 2, 8, 8, 12, 0, 4, 0], [8, 4, 4, 6, 6, 0, 4, 0, 16, 0, 3, 2], [4, 6, 7, 2, 10, 0, 3, 3, 7, 11, 21, 0], [0, 8, 1, 3, 14, 0, 7, 0, 5, 3, 6, 2], [0, 6, 2, 3, 5, 0, 3, 2, 13, 0, 2, 2], [1, 2, 5, 2, 8, 6, 3, 0, 5, 0, 11, 0], [0, 0, 6, 0, 8, 0, 5, 0, 3, 3, 12, 0], [8, 7, 1, 3, 8, 0, 8, 14, 4, 1, 6, 2], [7, 4, 4, 8, 10, 10, 6, 0, 9, 0, 5, 0], [0, 3, 6, 5, 9, 0, 5, 3, 3, 4, 4, 4], [0, 7, 4, 2, 16, 0, 4, 2, 6, 0, 12, 0], [4, 2, 0, 8, 4, 0, 1, 0, 9, 0, 7, 0], [6, 1, 3, 3, 3, 4, 4, 5, 2, 0, 6, 3], [3, 0, 4, 7, 4, 8, 6, 0, 4, 0, 6, 2], [6, 3, 1, 2, 2, 1, 5, 2, 6, 2, 4, 0], [2, 7, 3, 1, 6, 0, 13, 2, 5, 2, 5, 4], [2, 4, 5, 6, 18, 0, 8, 0, 5, 1, 3, 4], [4, 0, 6, 0, 8, 0, 14, 0, 3, 1, 7, 0], [5, 2, 1, 7, 4, 6, 10, 0, 15, 13, 8, 0], [3, 7, 6, 8, 6, 2, 14, 2, 3, 1, 7, 0], [4, 2, 7, 1, 14, 0, 6, 0, 13, 2, 8, 6], [0, 4, 2, 6, 2, 0, 7, 0, 27, 0, 3, 4], [6, 8, 5, 2, 3, 3, 7, 0, 8, 2, 25, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_offspring_with_repeated_models(offspring, dynamic_xu_xl):\n",
        "    \"\"\"\n",
        "    Validate offspring by detecting repeated models and adjusting parameters\n",
        "    based on the specified rules.\n",
        "\n",
        "    Parameters:\n",
        "    - offspring: List[int], the mutated offspring (models + parameters).\n",
        "    - dynamic_xu_xl: Function, returns dynamic bounds based on model keys.\n",
        "\n",
        "    Returns:\n",
        "    - validated_offspring: List[int], offspring after validation.\n",
        "    \"\"\"\n",
        "    # Extract models and parameters\n",
        "    model_keys = offspring[:4]\n",
        "    parameters = offspring[4:]\n",
        "\n",
        "    # Get dynamic bounds based on the model keys\n",
        "    dynamic_xl, dynamic_xu = dynamic_xu_xl(model_keys)\n",
        "\n",
        "    # Detect repeated models\n",
        "    unique_models = {}\n",
        "    for idx, model in enumerate(model_keys):\n",
        "        if model not in unique_models:\n",
        "            unique_models[model] = []\n",
        "        unique_models[model].append(idx)\n",
        "\n",
        "    # Process repeated models\n",
        "    for model, indices in unique_models.items():\n",
        "        if len(indices) > 1:  # Only process if model is repeated\n",
        "            # Collect the parameters associated with each repeated instance\n",
        "            repeated_params = [parameters[i * 2:(i + 1) * 2] for i in indices]\n",
        "\n",
        "            # Compare and update parameters\n",
        "            max_params = repeated_params[0]  # Start with the first instance's parameters\n",
        "            for i in range(1, len(repeated_params)):\n",
        "                current_params = repeated_params[i]\n",
        "                updated_params = []\n",
        "\n",
        "                for max_p, current_p, xl, xu in zip(max_params, current_params, dynamic_xl, dynamic_xu):\n",
        "                    # If the current parameter is less than or equal to the max, update it\n",
        "                    if current_p <= max_p:\n",
        "                        updated_params.append(min(max_p + 1, xu))  # Ensure within bounds\n",
        "                    else:\n",
        "                        updated_params.append(current_p)  # Keep as is if valid\n",
        "\n",
        "                # Update the offspring with the new parameters\n",
        "                parameters[indices[i] * 2:(indices[i] + 1) * 2] = updated_params\n",
        "                max_params = updated_params  # Update max_params for next comparison\n",
        "\n",
        "    # Combine models and validated parameters back into a single array\n",
        "    return model_keys + parameters\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "offspring =  [5, 5, 0, 5, 6, 3, 4, 3, 4, 0, 7, 1]\n",
        "  # Example offspring with repeated models\n",
        "validated_offspring = validate_offspring_with_repeated_models(offspring, dynamic_xu_xl)\n",
        "\n",
        "print(\"Validated Offspring:\")\n",
        "print(validated_offspring)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ5FWRot68vE",
        "outputId": "9102b353-0f94-4dc7-db8b-40ad93e8ba50"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validated Offspring:\n",
            "[5, 5, 0, 5, 6, 3, 7, 4, 4, 0, 8, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def validate_offspring_with_repeated_models(offspring, dynamic_xu_xl):\n",
        "    \"\"\"\n",
        "    Validate offspring by detecting repeated models and adjusting parameters\n",
        "    based on the specified rules.\n",
        "\n",
        "    Parameters:\n",
        "    - offspring: List[int], the mutated offspring (models + parameters).\n",
        "    - dynamic_xu_xl: Function, returns dynamic bounds based on model keys.\n",
        "\n",
        "    Returns:\n",
        "    - validated_offspring: List[int], offspring after validation.\n",
        "    \"\"\"\n",
        "    # Extract models and parameters\n",
        "    model_keys = offspring[:4]\n",
        "    parameters = offspring[4:]\n",
        "\n",
        "    # Get dynamic bounds based on the model keys\n",
        "    dynamic_xl, dynamic_xu = dynamic_xu_xl(model_keys)\n",
        "\n",
        "    # Detect repeated models\n",
        "    unique_models = {}\n",
        "    for idx, model in enumerate(model_keys):\n",
        "        if model not in unique_models:\n",
        "            unique_models[model] = []\n",
        "        unique_models[model].append(idx)\n",
        "\n",
        "    # Process repeated models\n",
        "    for model, indices in unique_models.items():\n",
        "        if len(indices) > 1:  # Only process if model is repeated\n",
        "            # Collect the parameters associated with each repeated instance\n",
        "            repeated_params = [parameters[i * 2:(i + 1) * 2] for i in indices]\n",
        "\n",
        "            # Compare and update parameters\n",
        "            max_params = repeated_params[0]  # Start with the first instance's parameters\n",
        "            for i in range(1, len(repeated_params)):\n",
        "                current_params = repeated_params[i]\n",
        "                updated_params = []\n",
        "\n",
        "                for max_p, current_p, xl, xu in zip(max_params, current_params, dynamic_xl, dynamic_xu):\n",
        "                    # If the current parameter is less than or equal to the max, update it\n",
        "                    if current_p <= max_p:\n",
        "                        updated_params.append(min(max_p + 1, xu))  # Ensure within bounds\n",
        "                    else:\n",
        "                        updated_params.append(current_p)  # Keep as is if valid\n",
        "\n",
        "                # Update the offspring with the new parameters\n",
        "                parameters[indices[i] * 2:(indices[i] + 1) * 2] = updated_params\n",
        "                max_params = updated_params  # Update max_params for next comparison\n",
        "\n",
        "    # Combine models and validated parameters back into a single array\n",
        "    return model_keys + parameters\n",
        "\n",
        "# Step 3: Round mutated offspring to the nearest integer\n",
        "mutated_Xp = [np.round(offspring).astype(int).tolist() for offspring in mutated_Xp]\n",
        "\n",
        "# Print the rounded mutated offsprings\n",
        "print(\"Rounded Mutated Offsprings:\")\n",
        "for offspring in mutated_Xp:\n",
        "    print(offspring)\n",
        "\n",
        "# Step 4: Apply semantic validation to the rounded offsprings\n",
        "validated_offsprings = [validate_offspring_with_repeated_models(offspring, dynamic_xu_xl) for offspring in mutated_Xp]\n",
        "\n",
        "# Print the validated offsprings after rounding\n",
        "print(\"\\nValidated Offsprings after Rounding and Validation:\")\n",
        "for validated in validated_offsprings:\n",
        "    print(validated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iwvn-sl7kzm",
        "outputId": "5f5e3b4e-6177-462e-e154-074cc990c314"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rounded Mutated Offsprings:\n",
            "[2, 4, 3, 1, 4, 0, 13, 0, 5, 2, 8, 5]\n",
            "[0, 4, 0, 0, 15, 0, 14, 0, 8, 0, 14, 0]\n",
            "[7, 6, 7, 3, 6, 11, 1, 3, 14, 6, 2, 2]\n",
            "[2, 3, 3, 7, 6, 0, 6, 3, 5, 2, 3, 8]\n",
            "[0, 1, 6, 1, 2, 0, 8, 8, 3, 1, 4, 2]\n",
            "[6, 4, 1, 5, 3, 1, 5, 0, 8, 2, 4, 8]\n",
            "[4, 4, 2, 0, 4, 0, 8, 0, 25, 0, 4, 0]\n",
            "[7, 5, 0, 8, 2, 2, 8, 8, 12, 0, 4, 0]\n",
            "[8, 4, 4, 6, 6, 0, 4, 0, 16, 0, 3, 2]\n",
            "[4, 6, 7, 2, 10, 0, 3, 3, 7, 11, 21, 0]\n",
            "[0, 8, 1, 3, 14, 0, 7, 0, 5, 3, 6, 2]\n",
            "[0, 6, 2, 3, 5, 0, 3, 2, 13, 0, 2, 2]\n",
            "[1, 2, 5, 2, 8, 6, 3, 0, 5, 0, 11, 0]\n",
            "[0, 0, 6, 0, 8, 0, 5, 0, 3, 3, 12, 0]\n",
            "[8, 7, 1, 3, 8, 0, 8, 14, 4, 1, 6, 2]\n",
            "[7, 4, 4, 8, 10, 10, 6, 0, 9, 0, 5, 0]\n",
            "[0, 3, 6, 5, 9, 0, 5, 3, 3, 4, 4, 4]\n",
            "[0, 7, 4, 2, 16, 0, 4, 2, 6, 0, 12, 0]\n",
            "[4, 2, 0, 8, 4, 0, 1, 0, 9, 0, 7, 0]\n",
            "[6, 1, 3, 3, 3, 4, 4, 5, 2, 0, 6, 3]\n",
            "[3, 0, 4, 7, 4, 8, 6, 0, 4, 0, 6, 2]\n",
            "[6, 3, 1, 2, 2, 1, 5, 2, 6, 2, 4, 0]\n",
            "[2, 7, 3, 1, 6, 0, 13, 2, 5, 2, 5, 4]\n",
            "[2, 4, 5, 6, 18, 0, 8, 0, 5, 1, 3, 4]\n",
            "[4, 0, 6, 0, 8, 0, 14, 0, 3, 1, 7, 0]\n",
            "[5, 2, 1, 7, 4, 6, 10, 0, 15, 13, 8, 0]\n",
            "[3, 7, 6, 8, 6, 2, 14, 2, 3, 1, 7, 0]\n",
            "[4, 2, 7, 1, 14, 0, 6, 0, 13, 2, 8, 6]\n",
            "[0, 4, 2, 6, 2, 0, 7, 0, 27, 0, 3, 4]\n",
            "[6, 8, 5, 2, 3, 3, 7, 0, 8, 2, 25, 0]\n",
            "\n",
            "Validated Offsprings after Rounding and Validation:\n",
            "[2, 4, 3, 1, 4, 0, 13, 0, 5, 2, 8, 5]\n",
            "[0, 4, 0, 0, 15, 0, 14, 0, 16, 0, 16, 0]\n",
            "[7, 6, 7, 3, 6, 11, 1, 3, 14, 12, 2, 2]\n",
            "[2, 3, 3, 7, 6, 0, 6, 3, 7, 0, 3, 8]\n",
            "[0, 1, 6, 1, 2, 0, 8, 8, 3, 1, 9, 0]\n",
            "[6, 4, 1, 5, 3, 1, 5, 0, 8, 2, 4, 8]\n",
            "[4, 4, 2, 0, 4, 0, 8, 0, 25, 0, 4, 0]\n",
            "[7, 5, 0, 8, 2, 2, 8, 8, 12, 0, 4, 0]\n",
            "[8, 4, 4, 6, 6, 0, 4, 0, 16, 0, 3, 2]\n",
            "[4, 6, 7, 2, 10, 0, 3, 3, 7, 11, 21, 0]\n",
            "[0, 8, 1, 3, 14, 0, 7, 0, 5, 3, 6, 2]\n",
            "[0, 6, 2, 3, 5, 0, 3, 2, 13, 0, 2, 2]\n",
            "[1, 2, 5, 2, 8, 6, 3, 0, 5, 0, 11, 1]\n",
            "[0, 0, 6, 0, 8, 0, 9, 0, 3, 3, 12, 0]\n",
            "[8, 7, 1, 3, 8, 0, 8, 14, 4, 1, 6, 2]\n",
            "[7, 4, 4, 8, 10, 10, 6, 0, 9, 1, 5, 0]\n",
            "[0, 3, 6, 5, 9, 0, 5, 3, 3, 4, 4, 4]\n",
            "[0, 7, 4, 2, 16, 0, 4, 2, 6, 0, 12, 0]\n",
            "[4, 2, 0, 8, 4, 0, 1, 0, 9, 0, 7, 0]\n",
            "[6, 1, 3, 3, 3, 4, 4, 5, 2, 0, 6, 3]\n",
            "[3, 0, 4, 7, 4, 8, 6, 0, 4, 0, 6, 2]\n",
            "[6, 3, 1, 2, 2, 1, 5, 2, 6, 2, 4, 0]\n",
            "[2, 7, 3, 1, 6, 0, 13, 2, 5, 2, 5, 4]\n",
            "[2, 4, 5, 6, 18, 0, 8, 0, 5, 1, 3, 4]\n",
            "[4, 0, 6, 0, 8, 0, 14, 0, 3, 1, 15, 0]\n",
            "[5, 2, 1, 7, 4, 6, 10, 0, 15, 13, 8, 0]\n",
            "[3, 7, 6, 8, 6, 2, 14, 2, 3, 1, 7, 0]\n",
            "[4, 2, 7, 1, 14, 0, 6, 0, 13, 2, 8, 6]\n",
            "[0, 4, 2, 6, 2, 0, 7, 0, 27, 0, 3, 4]\n",
            "[6, 8, 5, 2, 3, 3, 7, 0, 8, 2, 25, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Round mutated offspring to the nearest integer\n",
        "mutated_Xp = [np.round(offspring).astype(int).tolist() for offspring in mutated_Xp]\n",
        "\n",
        "# Apply the semantic validation to each offspring\n",
        "validated_mutated_Xp = [validate_offspring_with_repeated_models(offspring, dynamic_xu_xl) for offspring in mutated_Xp]\n",
        "\n",
        "# Print the validated offspring\n",
        "print(\"Validated Offsprings after Rounding and Validation:\")\n",
        "print(validated_mutated_Xp)\n"
      ],
      "metadata": {
        "id": "G2nez8qh9EMG",
        "outputId": "090fb975-5a65-4ef5-d784-55fd56e5c883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validated Offsprings after Rounding and Validation:\n",
            "[[2, 4, 3, 1, 4, 0, 13, 0, 5, 2, 8, 5], [0, 4, 0, 0, 15, 0, 14, 0, 16, 0, 16, 0], [7, 6, 7, 3, 6, 11, 1, 3, 14, 12, 2, 2], [2, 3, 3, 7, 6, 0, 6, 3, 7, 0, 3, 8], [0, 1, 6, 1, 2, 0, 8, 8, 3, 1, 9, 0], [6, 4, 1, 5, 3, 1, 5, 0, 8, 2, 4, 8], [4, 4, 2, 0, 4, 0, 8, 0, 25, 0, 4, 0], [7, 5, 0, 8, 2, 2, 8, 8, 12, 0, 4, 0], [8, 4, 4, 6, 6, 0, 4, 0, 16, 0, 3, 2], [4, 6, 7, 2, 10, 0, 3, 3, 7, 11, 21, 0], [0, 8, 1, 3, 14, 0, 7, 0, 5, 3, 6, 2], [0, 6, 2, 3, 5, 0, 3, 2, 13, 0, 2, 2], [1, 2, 5, 2, 8, 6, 3, 0, 5, 0, 11, 1], [0, 0, 6, 0, 8, 0, 9, 0, 3, 3, 12, 0], [8, 7, 1, 3, 8, 0, 8, 14, 4, 1, 6, 2], [7, 4, 4, 8, 10, 10, 6, 0, 9, 1, 5, 0], [0, 3, 6, 5, 9, 0, 5, 3, 3, 4, 4, 4], [0, 7, 4, 2, 16, 0, 4, 2, 6, 0, 12, 0], [4, 2, 0, 8, 4, 0, 1, 0, 9, 0, 7, 0], [6, 1, 3, 3, 3, 4, 4, 5, 2, 0, 6, 3], [3, 0, 4, 7, 4, 8, 6, 0, 4, 0, 6, 2], [6, 3, 1, 2, 2, 1, 5, 2, 6, 2, 4, 0], [2, 7, 3, 1, 6, 0, 13, 2, 5, 2, 5, 4], [2, 4, 5, 6, 18, 0, 8, 0, 5, 1, 3, 4], [4, 0, 6, 0, 8, 0, 14, 0, 3, 1, 15, 0], [5, 2, 1, 7, 4, 6, 10, 0, 15, 13, 8, 0], [3, 7, 6, 8, 6, 2, 14, 2, 3, 1, 7, 0], [4, 2, 7, 1, 14, 0, 6, 0, 13, 2, 8, 6], [0, 4, 2, 6, 2, 0, 7, 0, 27, 0, 3, 4], [6, 8, 5, 2, 3, 3, 7, 0, 8, 2, 25, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of validated offsprings:\", len(validated_mutated_Xp))\n",
        "for i, offspring in enumerate(validated_mutated_Xp):\n",
        "    print(f\"Offspring {i+1}: {offspring}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqZt9O0GuV-j",
        "outputId": "a16f2750-0390-45a7-9827-657532bfa89d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validated offsprings: 30\n",
            "Offspring 1: [2, 4, 3, 1, 4, 0, 13, 0, 5, 2, 8, 5]\n",
            "Offspring 2: [0, 4, 0, 0, 15, 0, 14, 0, 16, 0, 16, 0]\n",
            "Offspring 3: [7, 6, 7, 3, 6, 11, 1, 3, 14, 12, 2, 2]\n",
            "Offspring 4: [2, 3, 3, 7, 6, 0, 6, 3, 7, 0, 3, 8]\n",
            "Offspring 5: [0, 1, 6, 1, 2, 0, 8, 8, 3, 1, 9, 0]\n",
            "Offspring 6: [6, 4, 1, 5, 3, 1, 5, 0, 8, 2, 4, 8]\n",
            "Offspring 7: [4, 4, 2, 0, 4, 0, 8, 0, 25, 0, 4, 0]\n",
            "Offspring 8: [7, 5, 0, 8, 2, 2, 8, 8, 12, 0, 4, 0]\n",
            "Offspring 9: [8, 4, 4, 6, 6, 0, 4, 0, 16, 0, 3, 2]\n",
            "Offspring 10: [4, 6, 7, 2, 10, 0, 3, 3, 7, 11, 21, 0]\n",
            "Offspring 11: [0, 8, 1, 3, 14, 0, 7, 0, 5, 3, 6, 2]\n",
            "Offspring 12: [0, 6, 2, 3, 5, 0, 3, 2, 13, 0, 2, 2]\n",
            "Offspring 13: [1, 2, 5, 2, 8, 6, 3, 0, 5, 0, 11, 1]\n",
            "Offspring 14: [0, 0, 6, 0, 8, 0, 9, 0, 3, 3, 12, 0]\n",
            "Offspring 15: [8, 7, 1, 3, 8, 0, 8, 14, 4, 1, 6, 2]\n",
            "Offspring 16: [7, 4, 4, 8, 10, 10, 6, 0, 9, 1, 5, 0]\n",
            "Offspring 17: [0, 3, 6, 5, 9, 0, 5, 3, 3, 4, 4, 4]\n",
            "Offspring 18: [0, 7, 4, 2, 16, 0, 4, 2, 6, 0, 12, 0]\n",
            "Offspring 19: [4, 2, 0, 8, 4, 0, 1, 0, 9, 0, 7, 0]\n",
            "Offspring 20: [6, 1, 3, 3, 3, 4, 4, 5, 2, 0, 6, 3]\n",
            "Offspring 21: [3, 0, 4, 7, 4, 8, 6, 0, 4, 0, 6, 2]\n",
            "Offspring 22: [6, 3, 1, 2, 2, 1, 5, 2, 6, 2, 4, 0]\n",
            "Offspring 23: [2, 7, 3, 1, 6, 0, 13, 2, 5, 2, 5, 4]\n",
            "Offspring 24: [2, 4, 5, 6, 18, 0, 8, 0, 5, 1, 3, 4]\n",
            "Offspring 25: [4, 0, 6, 0, 8, 0, 14, 0, 3, 1, 15, 0]\n",
            "Offspring 26: [5, 2, 1, 7, 4, 6, 10, 0, 15, 13, 8, 0]\n",
            "Offspring 27: [3, 7, 6, 8, 6, 2, 14, 2, 3, 1, 7, 0]\n",
            "Offspring 28: [4, 2, 7, 1, 14, 0, 6, 0, 13, 2, 8, 6]\n",
            "Offspring 29: [0, 4, 2, 6, 2, 0, 7, 0, 27, 0, 3, 4]\n",
            "Offspring 30: [6, 8, 5, 2, 3, 3, 7, 0, 8, 2, 25, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Define the objective functions\n",
        "def f1(offspring):\n",
        "    \"\"\"Objective 1: Random FLOPs value in [-500, -100].\"\"\"\n",
        "    return np.random.uniform(-500, -100)\n",
        "\n",
        "def f2(offspring):\n",
        "    \"\"\"Objective 2: Random value in [0, 1].\"\"\"\n",
        "    return np.random.uniform(0, 1)\n",
        "\n",
        "# Step 2: Compute fitness values for validated offsprings\n",
        "fitness = []\n",
        "for offspring in validated_mutated_Xp:\n",
        "    f1_value = f1(offspring)\n",
        "    f2_value = f2(offspring)\n",
        "    fitness.append((f1_value, f2_value))\n",
        "\n",
        "# Step 3: Identify the Pareto front\n",
        "def pareto_front(fitness):\n",
        "    \"\"\"Identify Pareto front from a set of fitness values.\"\"\"\n",
        "    pareto = []\n",
        "    for i, f in enumerate(fitness):\n",
        "        dominated = False\n",
        "        for j, other in enumerate(fitness):\n",
        "            if j != i and other[0] <= f[0] and other[1] <= f[1] and (other[0] < f[0] or other[1] < f[1]):\n",
        "                dominated = True\n",
        "                break\n",
        "        if not dominated:\n",
        "            pareto.append(f)\n",
        "    return pareto\n",
        "\n",
        "pareto = pareto_front(fitness)\n",
        "\n",
        "# Step 4: Visualization of Pareto front\n",
        "if fitness:\n",
        "    f1_vals = [f[0] for f in fitness]\n",
        "    f2_vals = [f[1] for f in fitness]\n",
        "    pareto_f1 = [p[0] for p in pareto]\n",
        "    pareto_f2 = [p[1] for p in pareto]\n",
        "\n",
        "    plt.scatter(f1_vals, f2_vals, label=\"All Feasible Offspring\", color=\"blue\")\n",
        "    plt.scatter(pareto_f1, pareto_f2, label=\"Pareto Front\", color=\"red\")\n",
        "    plt.xlabel(\"f1 (FLOPs)\")\n",
        "    plt.ylabel(\"f2 (Random)\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Pareto Front for Validated Offspring\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No feasible solutions found.\")\n",
        "\n",
        "print(\"Fitness Values (f1, f2):\")\n",
        "for f in fitness:\n",
        "    print(f)\n",
        "\n",
        "print(\"\\nPareto Front:\")\n",
        "for p in pareto:\n",
        "    print(p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mJVLaz-ZuBs9",
        "outputId": "d4a584a9-8f50-433a-f23d-bb6320d384a1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAHHCAYAAAC/R1LgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfmUlEQVR4nO3deVxUVf8H8M8wyqrgggICAoq7uORCaLgkhWZuqJn7lku5hlr6ZG6VmKZBrmmGPpZLGaa5K8IvNdRUzI3MBRTZ3MEFQYfz+2OemRgYYICBWe7n/XrNC+fcc+89Z+6V+XK2KxNCCBARERFJgIWhC0BERERUXhj4EBERkWQw8CEiIiLJYOBDREREksHAh4iIiCSDgQ8RERFJBgMfIiIikgwGPkRERCQZDHyIiIhIMhj4EFGxpaWloV+/fqhevTpkMhlCQ0MNXaRi6dSpEzp16qR+n5CQAJlMhg0bNhS574gRI+Dp6VlmZSuJ6OhoyGQyREdHl8nx//zzT7Rr1w52dnaQyWQ4d+4cAGD//v1o0aIFrK2tIZPJ8OjRozI5vzbz5s2DTCYrt/OR+WDgQ0Zlw4YNkMlk6pe1tTXq16+PiRMnIi0trdzLk5ycjHnz5ql/0euL6otK2+vdd9/V67l0sXDhQvz666865//www9x4MABzJo1C5s2bULXrl3LpFwRERGQyWT47rvvCsxz6NAhyGQyfPPNN2VSBn0q7udcVi5duoQhQ4bA1dUVVlZWqFWrFgYPHoxLly7ly/vixQv0798fDx48wNdff41NmzbBw8MD9+/fxzvvvAMbGxusXLkSmzZtgp2dnQFqQ1Q8FQxdACJtFixYAC8vLzx//hzHjh3D6tWrsXfvXly8eBG2trblVo7k5GTMnz8fnp6eaNGihd6PP3nyZLRp00YjzRCtCQsXLkS/fv3Qu3dvnfIfOXIEvXr1wvTp08u0XN27d4eDgwM2b96M9957T2uezZs3Qy6Xlypg9PDwQGZmJipWrFjiY+iiuJ9zWYiIiMDAgQNRrVo1jB49Gl5eXkhISMD69euxfft2bN26FX369FHnv379Om7evIl169ZpXIP9+/fj8ePH+OyzzxAQEFDu9Zg9ezZmzpxZ7ucl08fAh4xSt27d0Lp1awDAe++9h+rVq2PZsmXYuXMnBg4cWOLj5uTkIDs7G9bW1voqaqn4+/ujX79+OuV9+fIlcnJyYGlpWcalKtqdO3dQpUoVvR3v+fPnsLS0hIWFZiO0lZUV+vXrh/DwcCQnJ6NWrVr59tuxYwfeeOMN1KxZs8TnV7Uumrvr169j6NChqFOnDn7//XfUqFFDvW3KlCnw9/fH0KFDcf78edSpUweA8loDyHe9C0ova0+fPoWdnR0qVKiAChX4FUbFx64uMgmvv/46ACA+Ph4A8NVXX6Fdu3aoXr06bGxs0KpVK2zfvj3ffjKZDBMnTsSPP/6IJk2awMrKCvv37wcAJCUlYdSoUXBycoKVlRWaNGmC77//Xr1vdHS0ujVm5MiR6q6o3ONAfv75Z7Rq1Qo2NjZwdHTEkCFDkJSUVOr6qsacfPXVVwgNDUXdunVhZWWFy5cvA1C2uPj7+8POzg5VqlRBr169EBcXp3EM1RiIa9euYcSIEahSpQocHBwwcuRIPHv2TOMzevr0KTZu3Kiu44gRI7SWS9UVKYTAypUr1flVbty4gf79+6NatWqwtbXFq6++ij179mgcQ9XNt3XrVsyePRuurq6wtbVFRkaG1nMOGTIEOTk52Lp1a75te/bsQXp6OgYPHgwACA8Px+uvv46aNWvCysoKjRs3xurVq3X+vPOO8fn111/RtGlTWFtbo2nTptixY4fW/XW5H4v6nIu6H1Vu376N3r17w87ODjVr1sSHH36IrKysIusIAEuWLMGzZ8+wdu1ajaAHABwdHfHtt9/i6dOnWLx4MQDleKaOHTsCAPr37w+ZTKYeHzV8+HAAQJs2bTTqcvXqVfTt2xfOzs6wtraGm5sb3n33XaSnp2t8Fqr/lw0aNIC1tTVatWqF33//XaNMqnv48uXLGDRoEKpWrYrXXntNY1vez3jixInq66b6HFX/53OLjo5G69atYW1tjbp16+Lbb7/luCGJYLhMJuH69esAgOrVqwMAwsLC0LNnTwwePBjZ2dnYunUr+vfvj927d6N79+4a+x45cgQ//fQTJk6cCEdHR3h6eiItLQ2vvvqq+hdljRo1sG/fPowePRoZGRmYOnUqGjVqhAULFmDOnDkYO3Ys/P39AQDt2rUDoAwCRo4ciTZt2iAkJARpaWkICwvD8ePHERsbq9Nfwo8fP8a9e/c00qpVq6b+d3h4OJ4/f46xY8fCysoK1apVw+HDh9GtWzfUqVMH8+bNQ2ZmJpYvX4727dvj7Nmz+brK3nnnHXh5eSEkJARnz57Fd999h5o1a+LLL78EAGzatAnvvfce2rZti7FjxwIA6tatq7W8HTp0wKZNmzB06FC88cYbGDZsmHpbWloa2rVrh2fPnmHy5MmoXr06Nm7ciJ49e2L79u0a3ScA8Nlnn8HS0hLTp09HVlZWgS1ZHTp0gJubGzZv3ozg4GCNbZs3b4atra2662j16tVo0qQJevbsiQoVKuC3337DBx98gJycHEyYMKGAq6DdwYMH0bdvXzRu3BghISG4f/8+Ro4cCTc3t3x5dbkfC/ucdbkfASAzMxNdunTBrVu3MHnyZNSqVQubNm3CkSNHdKrTb7/9Bk9PT/W9nFeHDh3g6empDlbHjRsHV1dXLFy4UN0t6+TkBABo0KAB1q5dq+6Wrlu3LrKzsxEYGIisrCxMmjQJzs7OSEpKwu7du/Ho0SM4ODioz/V///d/2LZtGyZPngwrKyusWrUKXbt2xalTp9C0aVONcvXv3x/16tXDwoULIYQotI7Hjh1DREQEPvjgA1SuXBnffPMN+vbti1u3bql/f8TGxqJr165wcXHB/PnzoVAosGDBgnzBIJkpQWREwsPDBQBx+PBhcffuXZGYmCi2bt0qqlevLmxsbMTt27eFEEI8e/ZMY7/s7GzRtGlT8frrr2ukAxAWFhbi0qVLGumjR48WLi4u4t69exrp7777rnBwcFAf/88//xQARHh4eL7z1axZUzRt2lRkZmaq03fv3i0AiDlz5hRaz6ioKAFA6ys+Pl7Ex8cLAMLe3l7cuXNHY98WLVqImjVrivv376vT/vrrL2FhYSGGDRumTps7d64AIEaNGqWxf58+fUT16tU10uzs7MTw4cMLLXNuAMSECRM00qZOnSoAiKNHj6rTHj9+LLy8vISnp6dQKBQada9Tp06+61iQGTNmCADiypUr6rT09HRhbW0tBg4cqE7TdrzAwEBRp04djbSOHTuKjh07qt+rPu/c17lFixbCxcVFPHr0SJ128OBBAUB4eHhoHE/X+7Ggz1nX+zE0NFQAED/99JM6z9OnT4W3t7cAIKKiovIdW+XRo0cCgOjVq1eBeYQQomfPngKAyMjIEEL8e71+/vlnjXyq/6t//vmnOi02NlZr3rxU9/rp06fVaTdv3hTW1taiT58+6jTVPZz7Gufdlve4lpaW4tq1a+q0v/76SwAQy5cvV6f16NFD2NraiqSkJHXa1atXRYUKFfIdk8wPu7rIKAUEBKBGjRpwd3fHu+++i0qVKmHHjh1wdXUFANjY2KjzPnz4EOnp6fD398fZs2fzHatjx45o3Lix+r0QAr/88gt69OgBIQTu3bunfgUGBiI9PV3rcXI7ffo07ty5gw8++EBjbEj37t3RsGHDfN07BZkzZw4OHTqk8XJ2dlZv79u3r8ZfoSkpKTh37hxGjBih0TLUrFkzvPHGG9i7d2++c4wfP17jvb+/P+7fv19g11JJ7d27F23btlV3RQBApUqVMHbsWCQkJKi76VSGDx+ucR0LM2TIEADKFh6VX375Bc+fP1d3cwGa90V6ejru3buHjh074saNGxpdLUVRfc7Dhw/XaKV44403NO4lbect6n7Mqzj34969e+Hi4qIxLszW1lbdglSYx48fAwAqV65caD7V9pLcH6rP6sCBAxrdqdr4+fmhVatW6ve1a9dGr169cODAASgUCo28ee/hwgQEBGi0WDZr1gz29va4ceMGAEChUODw4cPo3bu3xpgxb29vdOvWTefzkOliVxcZpZUrV6J+/fqoUKECnJyc0KBBA42Br7t378bnn3+Oc+fOaYxv0NY/7+XlpfH+7t27ePToEdauXYu1a9dqPb9q4GZBbt68CUDZ3J9Xw4YNcezYsUL3V/Hx8Sl0Rkzeshd23kaNGuHAgQPqwZ8qtWvX1shXtWpVAMovaHt7e53KqYubN2/C19dXa7lU23N3YeStW2GaNWuGpk2bYsuWLZg3bx4AZRDk6OiIwMBAdb7jx49j7ty5iImJyffFm56erhHEFFUXAKhXr16+bQ0aNMgX0BTnfsyrOPfjzZs34e3tne+42u6HvFQBjSoAKoiuAZI2Xl5eCA4OxrJly/Djjz/C398fPXv2xJAhQ/J99to+2/r16+PZs2e4e/euxh8AxblX8t7vgPKef/jwIQDlZ5mZmQlvb+98+bSlkflh4ENGqW3btupZXXkdPXoUPXv2RIcOHbBq1Sq4uLigYsWKCA8P12gRUMnbqpCTkwNA2YqgGqCZV7NmzUpZA/3QtUWkMHK5XGu6KGKsRFkrbt2GDBmCmTNn4vTp03Bzc0NUVBTGjRunntlz/fp1dOnSBQ0bNsSyZcvg7u4OS0tL7N27F19//bX6uutbce/HvMrrfnRwcICLiwvOnz9faL7z58/D1dW1xEHx0qVLMWLECOzcuRMHDx7E5MmTERISghMnTmgdH6WL4twrxnq/k/Fg4EMm55dffoG1tTUOHDgAKysrdXp4eLhO+9eoUQOVK1eGQqEocv2Rgv5i9/DwAABcuXJFPeNM5cqVK+rt+pb7vHn9/fffcHR0LNEicvqYyeLh4VFguVTbS2PgwIGYNWsWNm/eDA8PDygUCo1urt9++w1ZWVnYtWuXxl/9UVFRxT6XqqxXr17Nty1vHYtzP2r7nItzP3p4eODixYsQQmgcS9vnrs3bb7+NdevW4dixYxpdkipHjx5FQkICxo0bp9PxCuLj4wMfHx/Mnj0bf/zxB9q3b481a9bg888/V+fR9tn+888/sLW1LdNBxjVr1oS1tTWuXbuWb5u2NDI/HONDJkcul0Mmk2mMA0hISNB5RVy5XI6+ffvil19+wcWLF/Ntv3v3rvrfqiAi71L8rVu3Rs2aNbFmzRqNro19+/YhLi4u38wyfXFxcUGLFi2wceNGjTJdvHgRBw8exFtvvVWi49rZ2ZX6cQNvvfUWTp06hZiYGHXa06dPsXbtWnh6emodG1MctWvXhr+/P7Zt24YffvgBXl5e6hl2wL9/6ef+yz49PV3ngDi33J9z7rFBhw4dyjdWqTj3o7bPuTj341tvvYXk5GSNqfKq6em6mDFjBmxsbDBu3Djcv39fY9uDBw8wfvx42NraYsaMGTodL6+MjAy8fPlSI83HxwcWFhb5ptzHxMRodBkmJiZi586dePPNNwtstdEHuVyOgIAA/Prrr0hOTlanX7t2Dfv27Suz85LxYIsPmZzu3btj2bJl6Nq1KwYNGoQ7d+5g5cqV8Pb2LrIZX2XRokWIioqCr68vxowZg8aNG+PBgwc4e/YsDh8+jAcPHgBQTjeuUqUK1qxZg8qVK8POzg6+vr7w8vLCl19+iZEjR6Jjx44YOHCgejq7p6cnPvzwwzKr/5IlS9CtWzf4+flh9OjR6unsDg4O6vEvxdWqVSscPnwYy5YtQ61ateDl5aV1vE5hZs6ciS1btqBbt26YPHkyqlWrho0bNyI+Ph6//PJLvsUJS2LIkCEYO3YskpOT8cknn2hse/PNN2FpaYkePXpg3LhxePLkCdatW4eaNWsiJSWl2OcKCQlB9+7d8dprr2HUqFF48OABli9fjiZNmuDJkyfqfMW5Hwv6nHW9H8eMGYMVK1Zg2LBhOHPmDFxcXLBp0yadVzOvV68eNm7ciMGDB8PHxyffys337t3Dli1bClzOoChHjhzBxIkT0b9/f9SvXx8vX77Epk2b1MFdbk2bNkVgYKDGdHYAmD9/fonOXRzz5s3DwYMH0b59e7z//vtQKBRYsWIFmjZtqvfH05ARMtyEMqL8tE2R1Wb9+vWiXr16wsrKSjRs2FCEh4cXOL0177RrlbS0NDFhwgTh7u4uKlasKJydnUWXLl3E2rVrNfLt3LlTNG7cWD3VNfeU523btomWLVsKKysrUa1aNTF48GD1lPvCFDRFWEU1vXrJkiVatx8+fFi0b99e2NjYCHt7e9GjRw9x+fJljTyqz+Pu3bsa6arPOD4+Xp32999/iw4dOggbGxsBoMip7QV9rtevXxf9+vUTVapUEdbW1qJt27Zi9+7dxap7YR48eCCsrKwEgHz1FUKIXbt2iWbNmglra2vh6ekpvvzyS/H999/nq68u09mFEOKXX34RjRo1ElZWVqJx48YiIiJCDB8+PN90dl3vx8I+Z13vx5s3b4qePXsKW1tb4ejoKKZMmSL2799f5HT23M6fPy8GDhwoXFxc1OcaOHCguHDhQr68xZnOfuPGDTFq1ChRt25dYW1tLapVqyY6d+4sDh8+rLGv6v754Ycf1J9by5Yt85W/oHs49zZtx83Lw8Mj3z0dGRkpWrZsKSwtLUXdunXFd999J6ZNmyasra21fmZkPmRCcMQXERGVH5lMhgkTJmDFihWGLoqG3r1749KlS1rHH5H54BgfIiKSnMzMTI33V69exd69e9GpUyfDFIjKDcf4EBGR5NSpUwcjRoxAnTp1cPPmTaxevRqWlpb46KOPDF00KmMMfIiISHK6du2KLVu2IDU1FVZWVvDz88PChQu1LqxI5oVjfIiIiEgyOMaHiIiIJIOBDxEREUmG5Mb45OTkIDk5GZUrV9bLMv1ERERU9oQQePz4MWrVqlWqBVElF/gkJyfD3d3d0MUgIiKiEkhMTCzxA28BCQY+lStXBqD84Er69GEiIiIqXxkZGXB3d1d/j5eU5AIfVfeWvb09Ax8iIiITU9phKhzcTERERJLBwIeIiIgkg4EPERERSYbkxvgQERmjnJwcZGdnG7oYRAZlaWlZqqnqumDgQ0RkYNnZ2YiPj0dOTo6hi0JkUBYWFvDy8oKlpWWZnYOBDxGRAQkhkJKSArlcDnd39zL/a5fIWKkWGE5JSUHt2rXLbJFhBj5ERAb08uVLPHv2DLVq1YKtra2hi0NkUDVq1EBycjJevnyJihUrlsk5DPqnxe+//44ePXqgVq1akMlk+PXXX4vcJzo6Gq+88gqsrKzg7e2NDRs2lHk5iYjKikKhAIAybdonMhWq/weq/xdlwaCBz9OnT9G8eXOsXLlSp/zx8fHo3r07OnfujHPnzmHq1Kl47733cODAgTIuKRFR2eKzA4nK5/+BQbu6unXrhm7duumcf82aNfDy8sLSpUsBAI0aNcKxY8fw9ddfIzAwsKyKSUTlSKEAjh4FUlIAFxfA3x+Qyw1dKiIyFyY1ii4mJgYBAQEaaYGBgYiJiSlwn6ysLGRkZGi8SPnlEh0NbNmi/FmGrYpEOouIADw9gc6dgUGDlD89PZXpZHqio6Mhk8nw6NEjAMCGDRtQpUoVg5apMCNGjEDv3r3V7zt16oSpU6cWuo+npydCQ0PLtFy5HT9+HD4+PqhYsaK6rNrSysK8efPQokWLMjt+eTGpwCc1NRVOTk4aaU5OTsjIyEBmZqbWfUJCQuDg4KB+8cns/HIh4xQRAfTrB9y+rZmelKRM5/1pnGJiYiCXy9G9e3e9HE8mk+V7vfbaa3o5dlHCwsIMNm509+7d6NixIypXrgxbW1u0adNGa1mCg4PRokULxMfHq7drSysL06dPR2RkZJkdv7yYVOBTErNmzUJ6err6lZiYaOgiGRS/XMgYKRTAlCmAEPm3qdKmTmXLZGEM1Yq7fv16TJo0Cb///juSk5P1cszw8HCkpKSoX7t27dLLcYvi4OBgkBap5cuXo1evXmjfvj1OnjyJ8+fP491338X48eMxffp0jbzXr1/H66+/Djc3N3VZtaXpkxACL1++RKVKlVC9enW9H7+8mVTg4+zsjLS0NI20tLQ02Nvbw8bGRus+VlZW6iexS/2J7PxyIWN19Gj+YDw3IYDERGU+ys9QrbhPnjzBtm3b8P7776N79+56a22oUqUKnJ2d1a9q1aoBUA5dmD59OlxdXWFnZwdfX19ER0er97t//z4GDhwIV1dX2NrawsfHB1u2bNE49vbt2+Hj4wMbGxtUr14dAQEBePr0KYD8XV2AcrmBiRMnwsHBAY6Ojvj0008htP0S/Z9Hjx7hvffeQ40aNWBvb4/XX38df/31V4H5ExMTMW3aNEydOhULFy5E48aN4e3tjWnTpmHJkiVYunQpTp48iYSEBMhkMty/fx+jRo2CTCbDhg0btKY9fPgQgwcPRo0aNWBjY4N69eohPDwcANTH2bp1K9q1awdra2s0bdoU//d//6cuk6qLct++fWjVqhWsrKxw7NixfF1dqs/rq6++gouLC6pXr44JEybgxYsX6jwpKSno3r07bGxs4OXlhc2bN5d792BeJhX4+Pn55WtmO3ToEPz8/AxUItPCLxcyVikp+s0nJYZsxf3pp5/QsGFDNGjQAEOGDMH3339faFBQWhMnTkRMTAy2bt2K8+fPo3///ujatSuuXr0KAHj+/DlatWqFPXv24OLFixg7diyGDh2KU6dOAVB+CQ8cOBCjRo1CXFwcoqOjERQUVGiZN27ciAoVKuDUqVMICwvDsmXL8N133xWYv3///rhz5w727duHM2fO4JVXXkGXLl3w4MEDrfm3b9+OFy9e5GvZAYBx48ahUqVK2LJlC9zd3ZGSkgJ7e3uEhoYiJSUF/fv3z5c2YMAAfPrpp7h8+TL27duHuLg4rF69Go6OjhrHnjFjBqZNm4bY2Fj4+fmhR48euH//vkaemTNnYtGiRYiLi0OzZs20lj8qKgrXr19HVFQUNm7ciA0bNmgEwMOGDUNycjKio6Pxyy+/YO3atbhz506Bn1+5EAb0+PFjERsbK2JjYwUAsWzZMhEbGytu3rwphBBi5syZYujQoer8N27cELa2tmLGjBkiLi5OrFy5UsjlcrF//36dz5meni4AiPT0dL3Xx9ht3iyEMrwp/LV5s6FLSlITFaXbvRkVZeiS6l9mZqa4fPmyyMzMLPa+L18K4eZW8Oclkwnh7q7MVxbatWsnQkNDhRBCvHjxQjg6OoqoXBcpKipKABAPHz4UQggRHh4uHBwcCj0mAGFtbS3s7OzUrx07doibN28KuVwukpKSNPJ36dJFzJo1q8Djde/eXUybNk0IIcSZM2cEAJGQkKA17/Dhw0WvXr3U7zt27CgaNWokcnJy1Gkff/yxaNSokfq9h4eH+Prrr4UQQhw9elTY29uL58+faxy3bt264ttvv9V6zvHjxxf6mTRr1kx069ZN/d7BwUGEh4dr5Mmb1qNHDzFy5Eitx4uPjxcAxKJFi9RpL168EG5ubuLLL78UQvx73X799VeNfefOnSuaN2+ufj98+HDh4eEhXua6wfr37y8GDBgghBAiLi5OABB//vmnevvVq1cFAPVnlldh/x/09f1t0Onsp0+fRufOndXvg4ODAQDDhw/Hhg0bkJKSglu3bqm3e3l5Yc+ePfjwww8RFhYGNzc3fPfdd5zKriMXF/3mI9IXf3/AzU3ZSqHtj2+ZTLnd37/8y2bMitOK26mTfs995coVnDp1Cjt27AAAVKhQAQMGDMD69evRqZQn+/rrrzVm8Lq4uCA6OhoKhQL169fXyJuVlaUed6JQKLBw4UL89NNPSEpKQnZ2NrKystQrYjdv3hxdunSBj48PAgMD8eabb6Jfv36oWrVqgWV59dVXNdaW8fPzw9KlS6FQKCDPs87CX3/9hSdPnuQbB5OZmYnr16+X7MMogffffx99+/bF2bNn8eabb6J3795o166dRp7cPSUVKlRA69atERcXp5GndevWRZ6rSZMmGp+Di4sLLly4AEB5j1SoUAGvvPKKeru3t3ehn3d5MGjg06lTp0KbGLX1F3fq1AmxsbFlWCrzxS8XMlZyORAWpuyakck070/Vd05oKNfzycuQXYTr16/Hy5cvUatWLXWaEAJWVlZYsWIFHBwcSnxsZ2dneHt7a6Q9efIEcrkcZ86cyRdwVKpUCQCwZMkShIWFITQ0FD4+PrCzs8PUqVPVT72Xy+U4dOgQ/vjjDxw8eBDLly/HJ598gpMnT8LLy6vE5c1dRlWQlldBg47r16+P9PR0JCcna3yWgPLhtdevX9doINBFt27dcPPmTezduxeHDh1Cly5dMGHCBHz11VfFOo6dnV2RefI+VkImkxn9w3ZNaowPlY7qywX498tEhV8uZGhBQcD27YCrq2a6m5syPSjIMOUyZoZqxX358iX++9//YunSpTh37pz69ddff6FWrVr5BhTrQ8uWLaFQKHDnzh14e3trvJydnQEo17Pp1asXhgwZgubNm6NOnTr4559/NI4jk8nQvn17zJ8/H7GxsbC0tFS3Wmlz8uRJjfcnTpxAvXr18gVfAPDKK68gNTUVFSpUyFfGvGNsVPr27YuKFSuqF+bNbc2aNXj69CkGDhxY5OeTV40aNTB8+HD88MMPCA0Nxdq1a/PVQ+Xly5c4c+YMGjVqVOzzFKZBgwZ4+fKlRmPFtWvX8PDhQ72ep7j4kFKJUX25TJmi2UTu5qYMevjlQoYUFAT06sWVm3VlqFbc3bt34+HDhxg9enS+lp2+ffti/fr1GD9+vF7PWb9+fQwePBjDhg3D0qVL0bJlS9y9exeRkZFo1qwZunfvjnr16mH79u34448/ULVqVSxbtgxpaWlo3LgxAGUQExkZiTfffBM1a9bEyZMncffu3UK/8G/duoXg4GCMGzcOZ8+exfLly7UGKQAQEBAAPz8/9O7dG4sXL0b9+vWRnJyMPXv2oE+fPlq7jmrXro3Fixdj2rRpsLa2xtChQ1GxYkXs3LkT//nPfzBt2jT4+voW67OaM2cOWrVqhSZNmiArKwu7d+/OV8eVK1eiXr16aNSoEb7++ms8fPgQo0aNKtZ5itKwYUMEBARg7NixWL16NSpWrIhp06bBxsbGoI9oYeAjQfxyIWMml+t/PIq5MlQX4fr16xEQEKC1O6tv375YvHgxzp8/r9+TQrm+z+eff45p06YhKSkJjo6OePXVV/H2228DAGbPno0bN24gMDAQtra2GDt2LHr37o309HQAgL29PX7//XeEhoYiIyMDHh4eWLp0aaGPTho2bBgyMzPRtm1byOVyTJkyBWPHjtWaVyaTYe/evfjkk08wcuRI3L17F87OzujQoUO+xXdzmzp1KurUqYOvvvoKYWFhUCgUaNKkCVavXo2RI0cW+3OytLTErFmzkJCQABsbG/j7+2Pr1q0aeRYtWoRFixbh3Llz8Pb2xq5duwpslSqN//73vxg9ejQ6dOgAZ2dnhISE4NKlS7C2ttb7uXQlE4UNsjFDGRkZcHBwQHp6uqTX9CEi4/D8+XPEx8fDy8urxF8GERH5W3Hd3dmKS/klJCTAy8sLsbGxBnn8xO3bt+Hu7o7Dhw+jS5cu+bYX9v9BX9/fbPEhIjJxbMUlY3XkyBE8efIEPj4+SElJwUcffQRPT0906NDBYGVi4ENEZAbYRUjG6MWLF/jPf/6DGzduoHLlymjXrh1+/PHHfLPByhMDHyIiIonw9PQs09W18woMDDS6tfY4nZ2IiIgkgy0+REQSJgTw5AmQnQ1YWgKVKuVf54uoMKZ2DzHwISKSqIcPlY+0+N/CxgCUX1zu7oCBnypAJsIU7yF2dRERSdDDh8D165pfWIDy/fXryu1EhTHVe4iBDxGRxKgeXlqYxETtq0ETAaZ9D7Gri6iEFAqum0KmSTUeozDZ2cp8lSuXT5nItJjyPcTAh6gEtK2U6+amfHwAV8olY1fUF1Zx85H0mPI9xK4uomKKiFA+Gyl30AMoHxTZr59yO5Exs7Qsfb4RI0ZAJpNBJpPB0tIS3t7eWLBgAV6+fKmfQhZgw4YNqFKlil6O5enpqa6D6uXm5qaXYxckOjoaMpkMjx49KtPzlDV93EOGwsCHqBgUCmVLj7Z+a1Xa1KnKfETlSqEAoqOBLVuUPwu5CStVKvoLSTUtuTBdu3ZFSkoKrl69imnTpmHevHlYsmRJsYsOAAqFAjk5OSXatzQWLFiAlJQU9Ss2NlZrvhcvXpRzyYybvu4hQ2DgQ1QMR4/mb+nJTTXg7+jR8isTESIiAE9PoHNnYNAg5U9PzwKbH2Uy5XTjwri7F70Wi5WVFZydneHh4YH3338fAQEB2LVrFwBg2bJl8PHxgZ2dHdzd3fHBBx/gyZMn6n1VLTe7du1C48aNYWVlhVu3biErKwvTp0+Hq6sr7Ozs4Ovri+joaADK1pKRI0ciPT1d3UIzb948AMDDhw8xbNgwVK1aFba2tujWrRuuXr1a5EdXuXJlODs7q181atT432ckw+rVq9GzZ0/Y2dnhiy++AACsXr0adevWhaWlJRo0aIBNmzbl+Wxl+O6779CnTx/Y2tqiXr166s8kISEBnTt3BgBUrVoVMpkMI0aMKLKMxkhf95AhMPAhKoaUFP3mIyq1Eva9Vq0K1K2b/692S0tleknWYLGxsUH2/wZ1WFhY4JtvvsGlS5ewceNGHDlyBB999JFG/mfPnuHLL7/Ed999h0uXLqFmzZqYOHEiYmJisHXrVpw/fx79+/dH165dcfXqVbRr1w6hoaGwt7dXt9BMnz4dgLLr7fTp09i1axdiYmIghMBbb71VqpaaefPmoU+fPrhw4QJGjRqFHTt2YMqUKZg2bRouXryIcePGYeTIkYiKitLYb/78+XjnnXdw/vx5vPXWWxg8eDAePHgAd3d3/PLLLwCAK1euICUlBWFhYSUun6GVxT1ULoTEpKenCwAiPT3d0EUhExQVJYSyXafwV1SUoUtKpiIzM1NcvnxZZGZmFn/nly+FcHMr+EaUyYRwd1fmK0BOjhAZGULcu6f8mZOj26mHDx8uevXq9b9j5IhDhw4JKysrMX36dK35f/75Z1G9enX1+/DwcAFAnDt3Tp128+ZNIZfLRVJSksa+Xbp0EbNmzVLv5+DgoLH9n3/+EQDE8ePH1Wn37t0TNjY24qeffiqwDh4eHsLS0lLY2dmpX2FhYUIIIQCIqVOnauRv166dGDNmjEZa//79xVtvvaV+D0DMnj1b/f7JkycCgNi3b58QQoioqCgBQDx8+LDAcpmakt5D2hT2/0Ff39+c1UVUDP7+ytlbSUnax/nIZMrt/v7lXzaSoOL0vRbw6HaZrOTTjXfv3o1KlSrhxYsXyMnJwaBBg9RdT4cPH0ZISAj+/vtvZGRk4OXLl3j+/DmePXsGW1tbAIClpSWaNWumPt6FCxegUChQv359jfNkZWWhevXqBZYjLi4OFSpUgK+vrzqtevXqaNCgAeLi4gqtw4wZMzS6mxwdHdX/bt26db7zjB07ViOtffv2+VptctfJzs4O9vb2uHPnTqHlMGWluYcMgYEPUTHI5cop6/36Kf+z5w5+VH3ZoaFcz4fKiYH7Xjt37ozVq1fD0tIStWrVQoUKyq+UhIQEvP3223j//ffxxRdfoFq1ajh27BhGjx6N7OxsdeBjY2MDWa5BIE+ePIFcLseZM2cgz/OfqFIZjZJ1dHSEt7e31m12dnYlOmbFihU13stkMoMM3CbtOMaHqJiCgoDt2wFXV810NzdlOtfxoXLj4qLffMVkZ2cHb29v1K5dWx30AMCZM2eQk5ODpUuX4tVXX0X9+vWRnJxc5PFatmwJhUKBO3fuwNvbW+Pl7OwMQNlKpMgzY61Ro0Z4+fIlTp48qU67f/8+rly5gsaNG+uptsrzHD9+XCPt+PHjxTqH5f8GxOStA5UftvgQlUBQENCrF1duJgMz0r5Xb29vvHjxAsuXL0ePHj1w/PhxrFmzpsj96tevj8GDB2PYsGFYunQpWrZsibt37yIyMhLNmjVD9+7d4enpiSdPniAyMhLNmzdXz5zq1asXxowZg2+//RaVK1fGzJkz4erqil69eumtXjNmzMA777yDli1bIiAgAL/99hsiIiJw+PBhnY/h4eEBmUyG3bt346233oKNjU2ZtWaRdmzxISohuVw5bGLgQOVPBj2moRjL3Rg/Vd8rkH/esAH7Xps3b45ly5bhyy+/RNOmTfHjjz8iJCREp33Dw8MxbNgwTJs2DQ0aNEDv3r3x559/onbt2gCAdu3aYfz48RgwYABq1KiBxYsXq/dr1aoV3n77bfj5+UEIgb179+brdiqN3r17IywsDF999RWaNGmCb7/9FuHh4ehUwPgpbVxdXTF//nzMnDkTTk5OmDhxot7KR7qRCWGMjxArOxkZGXBwcEB6ejrs7e0NXRwiKkfG+KiR58+fIz4+Hl5eXrC2ti7ZQbRVzN1dGfSw75VMSGH/H/T1/c2uLiKSBNVyN3n/1FMtd2PS47PY90qkMwY+RGT2inrUiEymfNRIr14mHCuo+l6JqFAc40Nmy6zGclCp8FEjRKTCFh8yS8Y4loMMh48aISIVtviQ2Snho4uonJVni5yBl7vRicTmmRBpVR7/Dxj4kFkpaiwHoBzLwW4vwyrmw8RLTbXcTUFPilY9adoQjxpRrVCsergnkZSp/h/kXblbn9jVRWZFD48uojJmiNlVxvyokQoVKsDW1hZ3795FxYoVYWHBv0dJmnJycnD37l3Y2tpqrASubwx8yKxwLIdxM+TsKtWjRrSN/TLkcjcymQwuLi6Ij4/HzZs3DVMIIiNhYWGB2rVrazzDTd8Y+JBZMYWxHFJm6BY5Y13uxtLSEvXq1WN3F0mepaVlmbd6MvAhs2Kkjy6i/zGGFjljXe7GwsKi5Cs3E5HO2JlMZsVIH11E/8MWOSIyNAY+ZHZUYzlcXTXT3dxM/LEEZsCYZ1cRkTSwq4vMkrGO5ZA6Y55dRUTSwMCHzJaxjuWQOmOdXUVE0sDAh4jKHVvkiMhQGPgQkUGwRY6IDIGDm4mIiEgyGPgQERGRZDDwISIiIslg4ENERESSwcCHiIiIJIOBDxEREUkGAx8iIiKSDAY+REREJBkMfIiIiEgyGPgQERGRZDDwISIiIslg4ENERESSwcCHiIiIJIOBDxEREUkGAx8iIiKSDAY+REREJBkMfIiIiEgyKhi6AEREZDgKBXD0KJCSAri4AP7+gFxu6FIRlR2Dt/isXLkSnp6esLa2hq+vL06dOlVo/tDQUDRo0AA2NjZwd3fHhx9+iOfPn5dTaYmIzEdEBODpCXTuDAwapPzp6alMJzJXBg18tm3bhuDgYMydOxdnz55F8+bNERgYiDt37mjNv3nzZsycORNz585FXFwc1q9fj23btuE///lPOZeciMi0RUQA/foBt29rpiclKdMZ/JC5kgkhhKFO7uvrizZt2mDFihUAgJycHLi7u2PSpEmYOXNmvvwTJ05EXFwcIiMj1WnTpk3DyZMncezYMZ3OmZGRAQcHB6Snp8Pe3l4/FSEiMiEKhbJlJ2/QoyKTAW5uQHw8u73IeOjr+9tgLT7Z2dk4c+YMAgIC/i2MhQUCAgIQExOjdZ927drhzJkz6u6wGzduYO/evXjrrbcKPE9WVhYyMjI0XkREUnb0aMFBDwAIASQmKvMRmRuDDW6+d+8eFAoFnJycNNKdnJzw999/a91n0KBBuHfvHl577TUIIfDy5UuMHz++0K6ukJAQzJ8/X69lJyIyZSkp+s1HZEoMPri5OKKjo7Fw4UKsWrUKZ8+eRUREBPbs2YPPPvuswH1mzZqF9PR09SsxMbEcS0xEZHxcXPSbj8iUGKzFx9HREXK5HGlpaRrpaWlpcHZ21rrPp59+iqFDh+K9994DAPj4+ODp06cYO3YsPvnkE1hY5I/jrKysYGVlpf8KkNnhtF6SCn9/5RiepCRlt1ZeqjE+/v7lXzaismawFh9LS0u0atVKY6ByTk4OIiMj4efnp3WfZ8+e5Qtu5P/7ZjLgGG0yA5zWS1IilwNhYcp/y2Sa21TvQ0MZ+JN5MmhXV3BwMNatW4eNGzciLi4O77//Pp4+fYqRI0cCAIYNG4ZZs2ap8/fo0QOrV6/G1q1bER8fj0OHDuHTTz9Fjx491AEQUXFxWi9JUVAQsH074Oqqme7mpkwPCjJMuYjKmkFXbh4wYADu3r2LOXPmIDU1FS1atMD+/fvVA55v3bql0cIze/ZsyGQyzJ49G0lJSahRowZ69OiBL774wlBVIBOnUABTpmhv7hdC+dfv1KlAr17865fMT1CQ8t5mFy9JiUHX8TEEruNDuUVHK7u1ihIVBXTqVNalISKigpj8Oj5ExoDTeomIpIWBD0kap/USEUkLAx+SNNW03rwzW1RkMsDdndN6iYjMBQMfkjRO6yUikhYGPiR5nNZLRCQdBp3OTmQsOK2XiEgaGPgQ/Y9czinrRETmjoGPAfHZUEREROWLgY+BREQoVwzO/ZgENzflQFuOKSEiIiobHNxsAHw2FBERkWEw8ClnRT0bClA+G0qhKNdiERERSQIDn3J29Gj+lp7chAASE5X5iIiISL8Y+JQzPhuKiIjIcBj4lDM+G4qIiMhwGPiUMz4bioiIyHAY+JQzPhuKiIjIcBj4GACfDUVERGQYXMDQQPhsKCIiovLHwMeA+GwoIiKi8sWuLiIiIpIMBj5EREQkGQx8iIiISDIY+BAREZFkMPAhIiIiyWDgQ0RERJLBwIeIiIgkg4EPERERSQYDHyIiIpIMBj5EREQkGQx8iIiISDIY+BAREZFkMPAhIiIiyWDgQ0RERJLBwIeIiIgkg4EPERERSUYFQxeAiIiIzINCARw9CqSkAC4ugL8/IJcbulSaGPgQERFRqUVEAFOmALdv/5vm5gaEhQFBQYYrV17s6iIiIqJSiYgA+vXTDHoAIClJmR4RYZhyacPAh4iIiEpMoVC29AiRf5sqbepUZT5jwMCHiIiISuzo0fwtPbkJASQmKvMZAwY+REREVGIpKfrNV9YY+BAREVGJubjoN19ZY+BDREREJebvr5y9JZNp3y6TAe7uynzGgIEPERERlZhcrpyyDuQPflTvQ0ONZz0fBj5ERERUKkFBwPbtgKurZrqbmzLdmNbx4QKGREREVGpBQUCvXly5mYiIiCRCLgc6dTJ0KQrHri4iIiKSDAY+REREJBkMfIiIiEgyGPgQERGRZDDwISIiIsko0ayurKwsnDx5Ejdv3sSzZ89Qo0YNtGzZEl5eXvouHxEREZHeFCvwOX78OMLCwvDbb7/hxYsXcHBwgI2NDR48eICsrCzUqVMHY8eOxfjx41G5cuWyKjMRERFRiejc1dWzZ08MGDAAnp6eOHjwIB4/foz79+/j9u3bePbsGa5evYrZs2cjMjIS9evXx6FDh8qy3ERERETFpnOLT/fu3fHLL7+gYsWKWrfXqVMHderUwfDhw3H58mWkGMvz54mIiIj+RyaEEIYuRHnKyMiAg4MD0tPTYW9vb+jiEBERkQ709f1d6kdWPHnyBDk5ORppDCiIiIjIGJVoOnt8fDy6d+8OOzs7ODg4oGrVqqhatSqqVKmCqlWr6ruMRERERHpRosBnyJAhePjwIb7//ntERkbiyJEjOHLkCKKionDkyJFiHWvlypXw9PSEtbU1fH19cerUqULzP3r0CBMmTICLiwusrKxQv3597N27tyTVICIiIokpUVfXX3/9hTNnzqBBgwalOvm2bdsQHByMNWvWwNfXF6GhoQgMDMSVK1dQs2bNfPmzs7PxxhtvoGbNmti+fTtcXV1x8+ZNVKlSpVTlICIiImkoUeDTpk0bJCYmljrwWbZsGcaMGYORI0cCANasWYM9e/bg+++/x8yZM/Pl//777/HgwQP88ccf6tllnp6epSoDERERSUeJAp/vvvsO48ePR1JSEpo2bZpvinuzZs2KPEZ2djbOnDmDWbNmqdMsLCwQEBCAmJgYrfvs2rULfn5+mDBhAnbu3IkaNWpg0KBB+PjjjyGXy0tSFSIiIpKQEgU+d+/exfXr19UtNQAgk8kghIBMJoNCoSjyGPfu3YNCoYCTk5NGupOTE/7++2+t+9y4cQNHjhzB4MGDsXfvXly7dg0ffPABXrx4gblz52rdJysrC1lZWer3GRkZulSRiIiIzFCJAp9Ro0ahZcuW2LJlC5ycnCCTyfRdLq1ycnJQs2ZNrF27FnK5HK1atUJSUhKWLFlSYOATEhKC+fPnl0v5iIiIyLiVKPC5efMmdu3aBW9v7xKf2NHREXK5HGlpaRrpaWlpcHZ21rqPi4sLKlasqNGt1ahRI6SmpiI7OxuWlpb59pk1axaCg4PV7zMyMuDu7l7ichMREZHpKtF09tdffx1//fVXqU5saWmJVq1aITIyUp2Wk5ODyMhI+Pn5ad2nffv2uHbtmsaCif/88w9cXFy0Bj0AYGVlBXt7e40XERERSVOJWnx69OiBDz/8EBcuXICPj0++wc09e/bU6TjBwcEYPnw4WrdujbZt2yI0NBRPnz5Vjx0aNmwYXF1dERISAgB4//33sWLFCkyZMgWTJk3C1atXsXDhQkyePLkk1SAiIiKJKVHgM378eADAggUL8m3TdXAzAAwYMAB3797FnDlzkJqaihYtWmD//v3qAc+3bt2ChcW/jVLu7u44cOAAPvzwQzRr1gyurq6YMmUKPv7445JUg4iIiCSGDyklIiIio6ev7+8SjfEhIiIiMkUlDnz+7//+Dz169IC3tze8vb3Rs2dPHD16VJ9lIyIiItKrEgU+P/zwAwICAmBra4vJkydj8uTJsLGxQZcuXbB582Z9l5GIiIhIL0o0xqdRo0YYO3YsPvzwQ430ZcuWYd26dYiLi9NbAfWNY3yIiIhMj0HH+Ny4cQM9evTIl96zZ0/Ex8eXuDBEREREZalEgY+7u7vGwoMqhw8f5qrIREREZLRKtI7PtGnTMHnyZJw7dw7t2rUDABw/fhwbNmxAWFiYXgtIRMZFoQCOHgVSUgAXF8DfH8j1FBkiIqNWosDn/fffh7OzM5YuXYqffvoJgHLcz7Zt29CrVy+9FpCIjEdEBDBlCnD79r9pbm5AWBgQFGS4chER6YoLGBKRTiIigH79gLy/MWQy5c/t2xn8EFHZ4QKGRFRuFAplS4+2P5NUaVOnKvMRERkznbu6qlatCpnqT7siPHjwoMQFIiLjc/SoZvdWXkIAiYnKfJ06lVuxiIiKTefAJzQ0VP3v+/fv4/PPP0dgYCD8/PwAADExMThw4AA+/fRTvReSiAwrJUW/+YiIDKVEY3z69u2Lzp07Y+LEiRrpK1aswOHDh/Hrr7/qq3x6xzE+RMUXHQ107lx0vqgotvgQUdnQ1/d3iQKfSpUq4dy5c/D29tZIv3btGlq0aIEnT56UuEBljYEPUfEpFICnJ5CUpH2cj0ymnN0VH8+p7URUNgw6uLl69erYuXNnvvSdO3eievXqJS4MERknuVw5ZR34dxaXiup9aCiDHiIyfiVax2f+/Pl47733EB0dDV9fXwDAyZMnsX//fqxbt06vBSQi4xAUpJyyrm0dn9BQTmUnItNQ4nV8Tp48iW+++Ub9QNJGjRph8uTJ6kDIWLGri6h0uHIzkekxh/+3Bh3jY8oY+BARkZSYy4rr+vr+LlFXFwDk5OTg2rVruHPnDnJycjS2dejQocQFIiIiIv0oaMX1pCRluhRXXC9Ri8+JEycwaNAg3Lx5E3l3l8lkUBjx8q1s8SEiIilQzcYsaPFRU5uNadBZXePHj0fr1q1x8eJFPHjwAA8fPlS/uGozERGR4RVnxXUpKVFX19WrV7F9+/Z86/gQERGRceCK69qVqMXH19cX165d03dZiIiISE9cXPSbz1yUqMVn0qRJmDZtGlJTU+Hj44OKFStqbG/WrJleCkdEREQl4++vHMNT1Irr/v7lXzZDKtHgZguL/A1FMpkMQggObiYiIjISqlldgGbwo1px3ZRmdRl0Ont8fHyJT0hERGTKTGkxQK64nh8XMCQiItKRqS4GaErBWkGMYuXmy5cv49atW8jOztZI79mzZ4kLVNYY+BARUUkUtBigKXYbmSKDBj43btxAnz59cOHCBfXYHkA5zgcAx/gQEZFZMbfFAE2RQRcwnDJlCry8vHDnzh3Y2tri0qVL+P3339G6dWtER0eXuDBkOAoFEB0NbNmi/GnEsSsRUbnjYoDmo0SDm2NiYnDkyBE4OjrCwsICFhYWeO211xASEoLJkycjNjZW3+WkMmSqfdZEROWFiwGajxK1+CgUClSuXBkA4OjoiOTkZACAh4cHrly5or/SUZlT9Vnn/UtG9QC7iAjDlIuIyJhwMUAlc+gdKFHg07RpU/z1118AlKs4L168GMePH8eCBQtQp04dvRaQyo5CoWzp0TbKS5U2dapp3thERPqkWgxQNZA5L5kMcHc378UAIyKU45w6dwYGDVL+9PQ0vT+QSxT4zJ49Gzk5OQCABQsWID4+Hv7+/ti7dy/CwsL0WkAqO7r2Wc+bZ7qRPRGRPsjlyu5/IH/wo3ofGmq+A5vNqXdAb+v4PHjwAFWrVlXP7DJWnNX1ry1blFG7rjjuh4ikTtuYSHd3814M0FhmtBl0Vpc21apVQ2pqKiZOnKivQ1IZK25ftClG9kRE+hQUBCQkAFFRwObNyp/x8eYb9ADmN6Ot2LO6Ll26hKioKFhaWuKdd95BlSpVcO/ePXz++ef49ttvOcbHhBT1ALu8hFBG9lOnAr16mW+TLhFRYeRyoFMnQ5ei/JjbjLZitfjs2rULLVu2xOTJkzF+/Hi0bt0aUVFRaNSoEf7++2/s2LEDly5dKquykp4V1mddEFOL7ImIqHTMbUZbsQKfzz//HBMmTEBGRgaWLVuGGzduYPLkydi7dy/279+Prl27llU5qYyoHmDn6lq8/UwlsiciotIxtxltxQp8rly5ggkTJqBSpUqYNGkSLCws8PXXX6NNmzZlVT4qB7n7rGfP1m0fU4nsiYiodMxtRluxAp/Hjx+rR1LL5XLY2NhwTI+ZUPVZz5tnXpE9ERGVXkG9A25upvdw1mIPbj5w4AAcHBwAADk5OYiMjMTFixc18hjz09mpcKrIvl8/ZZCTe9CzKUb2VDSFQjlmKyVF2ZLn78/rS0T5BQUpJ7aY+u+LYq3jY2FRdAORTCbj09nNgBTXqpAiPqeNiEyFvr6/9baAoalg4KM7tgSYN9VKrHl/A6ha9kyt+ZqIzBsDnxJi4ENkPCuxEhHpqtxXbj5x4oTOB3327BnX8yEyYua2EisRka50DnyGDh2KwMBA/Pzzz3j69KnWPJcvX8Z//vMf1K1bF2fOnNFbIYlIv8xtJVYiIl3pPKvr8uXLWL16NWbPno1Bgwahfv36qFWrFqytrfHw4UP8/fffePLkCfr06YODBw/Cx8enLMtNRKVgbiuxEhHpqkRjfE6fPo1jx47h5s2byMzMhKOjI1q2bInOnTujWrVqZVFOveEYH6J/x/gU9Jw2jvEhImOjr+/vYq/jAwCtW7dG69atS3xSIjIsrtdERFJVrJWbich8mNNKrEREuipRiw8RmQdzWYmViEhXDHyIJE71nDYiIilgVxcRERFJBgMfIiIikoxiBz6ZmZk4duwYLl++nG/b8+fP8d///lcvBSMiIiLSt2IFPv/88w8aNWqEDh06wMfHBx07dkRKrqVd09PTMXLkSL0XkoiIiEgfihX4fPzxx2jatCnu3LmDK1euoHLlymjfvj1u3bpVVuUjIiIi0ptiBT5//PEHQkJC4OjoCG9vb/z2228IDAyEv78/bty4UVZlJCIiItKLYgU+mZmZqFDh3xnwMpkMq1evRo8ePdCxY0f8888/ei8gERERkb4UK/Bp2LAhTp8+nS99xYoV6NWrF3r27FmiQqxcuRKenp6wtraGr68vTp06pdN+W7duhUwmQ+/evUt0XiIiIpKWYgU+ffr0wZYtW7RuW7FiBQYOHIjiPvN027ZtCA4Oxty5c3H27Fk0b94cgYGBuHPnTqH7JSQkYPr06fD39y/W+YiIiEi6dH46+/nz59GkSRPI9byWva+vL9q0aYMVK1YAAHJycuDu7o5JkyZh5syZWvdRKBTo0KEDRo0ahaNHj+LRo0f49ddfdTofn85ORERkevT1/a1zi0/Lli3x4MEDAECdOnVw//79Ep9UJTs7G2fOnEFAQMC/BbKwQEBAAGJiYgrcb8GCBahZsyZGjx5d5DmysrKQkZGh8SIiaVEogOhoYMsW5U+FwtAlIiJD0TnwqVKlinrmVkJCAnJyckp98nv37kGhUMDJyUkj3cnJCampqVr3OXbsGNavX49169bpdI6QkBA4ODioX+7u7qUuNxGZjogIwNMT6NwZGDRI+dPTU5lORNKj80NK+/bti44dO8LFxQUymQytW7cusNurrKa2P378GEOHDsW6devg6Oio0z6zZs1CcHCw+n1GRgaDHyKJiIgA+vUD8nboJyUp07dvVz6hnoikQ+fAZ+3atQgKCsK1a9cwefJkjBkzBpUrVy7VyR0dHSGXy5GWlqaRnpaWBmdn53z5r1+/joSEBPTo0UOdpmp5qlChAq5cuYK6detq7GNlZQUrK6tSlZOITI9CAUyZkj/oAZRpMhkwdSrQq5fyCfVEJA06Bz4A0LVrVwDAmTNnMGXKlFIHPpaWlmjVqhUiIyPVU9JzcnIQGRmJiRMn5svfsGFDXLhwQSNt9uzZePz4McLCwtiSQ0RqR48Ct28XvF0IIDFRma9Tp3IrFhEZWLECH5Xw8HC9FSA4OBjDhw9H69at0bZtW4SGhuLp06fqZ34NGzYMrq6uCAkJgbW1NZo2baqxf5UqVQAgXzoRSVuuxwjqJR8RmYcSBT76NGDAANy9exdz5sxBamoqWrRogf3796sHPN+6dQsWFsV+iDwRSZyLi37zEZF50HkdH3PBdXyIpEGhUM7eSkrSPs5HJgPc3ID4eI7xITIF5b6ODxGRKZHLgbAw5b9lMs1tqvehoQx6iKSGgQ8Rma2gIOWUdVdXzXQ3N05lJ5Iqg4/xISIqS0FByinrR48qBzK7uAD+/mzpIZIqBj5EZPbkck5ZJyIlBj5ERGT2FAq2+pESAx8iIjJrERHKVbxzL2jp5qYc/M5xXtLDwc1ERGS2VM9ry7uKt+p5bXxYrfQw8CEiIrNU1PPaAOXz2hSKci0WGRgDHyIiMkvFeV4bSQcDHyIiMkt8Xhtpw8CHiIjMEp/XRtow8CEiIrPk76+cvZX3kSUqMhng7q7MR9LBwIeIiMwSn9dG2jDwISIis8XntVFeXMCQiIjMGp/XRrkx8CEiIrNnbs9r4yM4So6BDxERkQnhIzhKh2N8iIiITAQfwVF6DHyIiIhMAB/BoR8MfIiIiEwAH8GhHwx8iIiITAAfwaEfDHyIiIhMAB/BoR8MfIiIiEwAH8GhHwx8iIiITAAfwaEfDHyIiIhMBB/BUXpcwJCIiMiE8BEcpcPAh4iIyMSY2yM4yhO7uoiIiEgyGPgQERGRZDDwISIiIslg4ENERESSwcCHiIiIJIOBDxEREUkGAx8iIiKSDAY+REREJBkMfIiIiEgyGPgQERGRZDDwISIiIslg4ENERESSwYeU6okiW4ELq47i2fUU2NZ1gc8H/pBb8lG5RERExoSBjx6c+CgCtZdNQQvFbXVa8nQ33AoOw6uLgwxYMiIiIsqNXV2ldOKjCLRd0g/OuYIeAHBWJKHtkn448VGEgUpGREREeTHwKQVFtgK1l00BIPJ9kBYQAAD3ZVOhyFaUe9mIiIgoPwY+pXBh1VHUUtwu8EO0gICrIhEXVh0t13IRERGRdgx8SuHZ9RS95iMiIqKyxcCnFGzruug1HxEREZUtBj6l4POBP5LlbsiBTOv2HMiQJHeHzwf+5VwyIiIi0oaBTynILeW4FRwGAPmCH9X7xOBQrudDRERkJBj4lNKri4NwasZ2pMpdNdJT5G44NWM71/EhIjIwhQKIjga2bFH+VHCiraTJhBDC0IUoTxkZGXBwcEB6ejrs7e31dlyu3ExEZHwiIoApU4DbuZZac3MDwsKAIP5dalL09f3NwIeIiMxSRATQrx+Q91tO9r+RCdu3M/gxJfr6/mZXFxERmR2FQtnSo+1Pe1Xa1Kns9pIiBj5ERGR2jh7V7N7KSwggMVGZj6SFgQ8REZmdFB3XjdU1H5kPBj5ERGR2XHRcN1bXfGQ+GPgQEZHZ8fdXzt6SaV9fFjIZ4O6uzEfSwsCHiIjMjlyunLIO5A9+VO9DQ5X5SFoY+BARkVkKClJOWXfVXF8Wbm6cyi5lFQxdACIiorISFAT06qWcvZWSohzT4+/Plh4pM4oWn5UrV8LT0xPW1tbw9fXFqVOnCsy7bt06+Pv7o2rVqqhatSoCAgIKzU9ERNImlwOdOgEDByp/MuiRNoMHPtu2bUNwcDDmzp2Ls2fPonnz5ggMDMSdO3e05o+OjsbAgQMRFRWFmJgYuLu7480330RSUlI5l5yIiIhMjcEfWeHr64s2bdpgxYoVAICcnBy4u7tj0qRJmDlzZpH7KxQKVK1aFStWrMCwYcOKzM9HVhAREZkes3hkRXZ2Ns6cOYOAgAB1moWFBQICAhATE6PTMZ49e4YXL16gWrVqWrdnZWUhIyND40VERETSZNDA5969e1AoFHByctJId3JyQmpqqk7H+Pjjj1GrVi2N4Cm3kJAQODg4qF/u7u6lLjcRERGZJoOP8SmNRYsWYevWrdixYwesra215pk1axbS09PVr8TExHIuJRERERkLg05nd3R0hFwuR1pamkZ6WloanJ2dC933q6++wqJFi3D48GE0a9aswHxWVlawsrLSS3mJiIjItBm0xcfS0hKtWrVCZGSkOi0nJweRkZHw8/MrcL/Fixfjs88+w/79+9G6devyKCoRERGZAYMvYBgcHIzhw4ejdevWaNu2LUJDQ/H06VOMHDkSADBs2DC4uroiJCQEAPDll19izpw52Lx5Mzw9PdVjgSpVqoRKlSoZrB5ERERk/Awe+AwYMAB3797FnDlzkJqaihYtWmD//v3qAc+3bt2ChcW/DVOrV69GdnY2+vXrp3GcuXPnYt68eeVZdCIiIjIxBl/Hp7xxHR8iIiLTYxbr+BARERGVJwY+REREJBkMfIiIiEgyGPgQERGRZDDwISIiIslg4ENERESSwcCHiIiIJIOBDxEREUkGAx8iIiKSDAY+REREJBkMfIiIiEgyGPgQERGRZDDwISIiIslg4ENERESSwcCHiIiIJIOBDxEREUkGAx8iIiKSDAY+REREJBkMfIiIiEgyGPgQERGRZDDwISIiIslg4ENERESSwcCHiIiIJIOBDxEREUkGAx8iIiKSDAY+REREJBkMfIiIiEgyGPgQERGRZDDwISIiIsmoYOgCEJF5UCiAo0eBlBTAxQXw9wfkckOXiohIEwMfIiq1iAhgyhTg9u1/09zcgLAwICjIcOUiIsqLXV1EVCoREUC/fppBDwAkJSnTIyIMUy4iIm0Y+BBRiSkUypYeIfJvU6VNnarMR2RKFAogOhrYskX5k/ew+WDgQ0QldvRo/pae3IQAEhOV+YhMRUQE4OkJdO4MDBqk/OnpydZLc8ExPkQF4GDdoqWk6DcfkaGpum7ztmKqum63b9cct8bfE6aHLT5EWvAvPt24uOg3H5EhFbfrlr8nTJNMCG2X2HxlZGTAwcEB6enpsLe3N3RxyAgV9BefTKb8mfcvPilTKJS/6JOStH9ZyGTK2V3x8fwrmIxfdLQyeClKVBTw4AF/T5Q3fX1/s8WHKBcO1i0euVw5ZR349xe+iup9aCiDHjINunbJJiXx94QpY+BDlAsH6xZfUJDyr1tXV810Nzf+1UumRdcu2bt3+XvClHFwM1EuHKxbMkFBQK9eHORJps3fXxmwF9V1W6OGbsfj7wnjxMCHKBcO1i05uRzo1MnQpSAqOVXXbb9+yiAnd/CTu+u2WjXdjsffE8aJXV1Euaj+4ss7XkVFJgPc3ZX5iMj86NJ1y98Tpo2BD1EuHKxbtrgaLpmCoCAgIUE5e2vzZuXP+Ph/x6vx94RpY+BDlAcH65YNrnlCpkTVdTtwoPJn3iCGvydMF9fxISoAV2TVH66NROaKvyfKj76+vxn4EFGZUi1yWND0Xy5ySES60Nf3N2d1SZQiW4ELq47i2fUU2NZ1gc8H/pBb8luH9K84ayNxVhgRlTUGPhJ04qMI1F42BS0U/34bJU93w63gMLy6mP0NpF9cG4mIjAkHN0vMiY8i0HZJPzgrNP8Ed1Ykoe2SfjjxEUeakn5xbSQiMiYc4yMhimwF0mw94ay4rTXizYEMKXI3OD+LZ7cX6Q0fZEpE+sCHlFKxXVh1FLUKCHoAwAICropEXFjFB8yQ/nDNEyIyJgx8JOTZdd0GUeiaj0hXXPOEiIwFBzdLiG1d3QZR6JqPqDj4IFMiMgYc4yMh/47xSYIF8l92jvEhIiJjxTE+VGxySzluBSsHW+RAc7CF6n1icCiDHiIiMlsMfCTm1cVBODVjO1LlmoMtUuRuODVjO9fxISIis8auLoniys1ERGRK+MgKKhW5pRwtpnYydDGIiIjKFbu6iIiISDKMIvBZuXIlPD09YW1tDV9fX5w6darQ/D///DMaNmwIa2tr+Pj4YO/eveVUUiIiIjJlBg98tm3bhuDgYMydOxdnz55F8+bNERgYiDt37mjN/8cff2DgwIEYPXo0YmNj0bt3b/Tu3RsXL14s55ITERGRqTH44GZfX1+0adMGK1asAADk5OTA3d0dkyZNwsyZM/PlHzBgAJ4+fYrdu3er01599VW0aNECa9asKfJ8HNxMRERkesxiHZ/s7GycOXMGAQEB6jQLCwsEBAQgJiZG6z4xMTEa+QEgMDCwwPxZWVnIyMjQeBEREZE0GTTwuXfvHhQKBZycnDTSnZyckJqaqnWf1NTUYuUPCQmBg4OD+uXu7q6fwhMREZHJMfgYn7I2a9YspKenq1+JiYmGLhIREREZiEHX8XF0dIRcLkdaWppGelpaGpydnbXu4+zsXKz8VlZWsLKy0k+BiYiIyKQZtMXH0tISrVq1QmRkpDotJycHkZGR8PPz07qPn5+fRn4AOHToUIH5iYiIiFQMvnJzcHAwhg8fjtatW6Nt27YIDQ3F06dPMXLkSADAsGHD4OrqipCQEADAlClT0LFjRyxduhTdu3fH1q1bcfr0aaxdu1an86kmsXGQMxERkelQfW+XejK6MALLly8XtWvXFpaWlqJt27bixIkT6m0dO3YUw4cP18j/008/ifr16wtLS0vRpEkTsWfPHp3PlZiYKADwxRdffPHFF18m+EpMTCxVzGHwdXzKW05ODpKTk1G5cmXIZLISHycjIwPu7u5ITEw06/WApFJPQDp1ZT3Nj1TqKpV6AtKpa3HqKYTA48ePUatWLVhYlHykjsG7usqbhYUF3Nzc9HY8e3t7s74pVaRST0A6dWU9zY9U6iqVegLSqauu9XRwcCj1ucx+OjsRERGRCgMfIiIikgwGPiVkZWWFuXPnmv0aQVKpJyCdurKe5kcqdZVKPQHp1NUQ9ZTc4GYiIiKSLrb4EBERkWQw8CEiIiLJYOBDREREksHAh4iIiCSDgU8RPD09IZPJNF6LFi3SyHP+/Hn4+/vD2toa7u7uWLx4cb7j/Pzzz2jYsCGsra3h4+ODvXv3llcVii0rKwstWrSATCbDuXPn1OkJCQn5PguZTIYTJ05o7G8qdS2onoD5XNOePXuidu3asLa2houLC4YOHYrk5GT1dnO5pkXVEzD9a5qQkIDRo0fDy8sLNjY2qFu3LubOnYvs7GyNPOZwPXWpK2D61xQAvvjiC7Rr1w62traoUqWK1jzarunWrVs18kRHR+OVV16BlZUVvL29sWHDhrIvfDHoUs9bt26he/fusLW1Rc2aNTFjxgy8fPlSI49e6lmqB15IgIeHh1iwYIFISUlRv548eaLenp6eLpycnMTgwYPFxYsXxZYtW4SNjY349ttv1XmOHz8u5HK5WLx4sbh8+bKYPXu2qFixorhw4YIhqlSkyZMni27dugkAIjY2Vp0eHx8vAIjDhw9rfB7Z2dnqPKZU14LqaU7XdNmyZSImJkYkJCSI48ePCz8/P+Hn56febi7XtKh6msM13bdvnxgxYoQ4cOCAuH79uti5c6eoWbOmmDZtmjqPuVxPXepqDtdUCCHmzJkjli1bJoKDg4WDg4PWPABEeHi4xjXNzMxUb79x44awtbUVwcHB4vLly2L58uVCLpeL/fv3l1MtilZUPV++fCmaNm0qAgICRGxsrNi7d69wdHQUs2bNUufRVz0Z+BTBw8NDfP311wVuX7VqlahatarIyspSp3388ceiQYMG6vfvvPOO6N69u8Z+vr6+Yty4cXovb2nt3btXNGzYUFy6dKnAwCd3Wl6mUtfC6mlu1zS3nTt3CplMpv4iNKdrmlveeprrNV28eLHw8vJSvzfX6ylE/rqa2zUNDw8vNPDZsWNHgft+9NFHokmTJhppAwYMEIGBgXosoX4UVM+9e/cKCwsLkZqaqk5bvXq1sLe3V19jfdWTXV06WLRoEapXr46WLVtiyZIlGk1vMTEx6NChAywtLdVpgYGBuHLlCh4+fKjOExAQoHHMwMBAxMTElE8FdJSWloYxY8Zg06ZNsLW1LTBfz549UbNmTbz22mvYtWuXxjZTqGtR9TSna5rbgwcP8OOPP6Jdu3aoWLGixjZTv6a5aaunuV7T9PR0VKtWLV+6OV1Plbx1NddrWpAJEybA0dERbdu2xffffw+Rawk+c6hnTEwMfHx84OTkpE4LDAxERkYGLl26pM6jj3oy8CnC5MmTsXXrVkRFRWHcuHFYuHAhPvroI/X21NRUjQsFQP0+NTW10Dyq7cZACIERI0Zg/PjxaN26tdY8lSpVwtKlS/Hzzz9jz549eO2119C7d2+NX6zGXldd6mku11Tl448/hp2dHapXr45bt25h586d6m3mcE1VCqunuV1TALh27RqWL1+OcePGqdPM6Xrmpq2u5nhNC7JgwQL89NNPOHToEPr27YsPPvgAy5cvV28vqJ4ZGRnIzMws7+KWSGmuZ3HrKcnAZ+bMmVoHi+V+/f333wCA4OBgdOrUCc2aNcP48eOxdOlSLF++HFlZWQauhW50revy5cvx+PFjzJo1q8BjOTo6Ijg4GL6+vmjTpg0WLVqEIUOGYMmSJeVYI+30WU9jV5z7FwBmzJiB2NhYHDx4EHK5HMOGDVP/tWgO11SlsHoas+LWEwCSkpLQtWtX9O/fH2PGjFGnG/P1BPRbV2NWknoW5tNPP0X79u3RsmVLfPzxx/joo4+M4prqu57lpYKhC2AI06ZNw4gRIwrNU6dOHa3pvr6+ePnyJRISEtCgQQM4OzsjLS1NI4/qvbOzs/qntjyq7WVJ17oeOXIEMTEx+Z6X0rp1awwePBgbN27Uuq+vry8OHTqkfm+ouuqznuZyTVUcHR3h6OiI+vXro1GjRnB3d8eJEyfg5+endV9Tu6YqhdXTmK9pceuZnJyMzp07o127dli7dm2RxzeW6wnot67mdE2Ly9fXF5999hmysrJgZWVVYD3t7e1hY2NT4vMURZ/1dHZ2xqlTpzTSdL2exa2nJAOfGjVqoEaNGiXa99y5c7CwsEDNmjUBAH5+fvjkk0/w4sUL9XiCQ4cOoUGDBqhatao6T2RkJKZOnao+zqFDhwr84tEnXev6zTff4PPPP1e/T05ORmBgILZt2wZfX98C9zt37hxcXFzU7w1VV33W01yuqTY5OTkAUGiLpaldU23y1tOYr2lx6pmUlITOnTujVatWCA8Ph4VF0Y32xnI9Af3W1VyuaUmcO3cOVatWVf8B5+fnl2+avqnV08/PD1988QXu3Lmj/n49dOgQ7O3t0bhxY3UevdSzWEOhJeaPP/4QX3/9tTh37py4fv26+OGHH0SNGjXEsGHD1HkePXoknJycxNChQ8XFixfF1q1bha2tbb4plRUqVBBfffWViIuLE3PnzjW6KZV5aZsdsmHDBrF582YRFxcn4uLixBdffCEsLCzE999/r85janXVVk9zuaYnTpwQy5cvF7GxsSIhIUFERkaKdu3aibp164rnz58LIczjmupST3O4prdv3xbe3t6iS5cu4vbt2xpTm1XM4XoKoVtdzeGaCiHEzZs3RWxsrJg/f76oVKmSiI2NFbGxseLx48dCCCF27dol1q1bJy5cuCCuXr0qVq1aJWxtbcWcOXPUx1BN854xY4aIi4sTK1euNLrp7EXVUzWd/c033xTnzp0T+/fvFzVq1NA6nb209WTgU4gzZ84IX19f4eDgIKytrUWjRo3EwoUL1b9MVf766y/x2muvCSsrK+Hq6ioWLVqU71g//fSTqF+/vrC0tBRNmjQRe/bsKa9qlEhBgU+jRo2Era2tsLe3F23bthU///xzvn1Nqa4FTf81h2t6/vx50blzZ1GtWjVhZWUlPD09xfjx48Xt27fVeczhmupSTyFM/5qGh4cLAFpfKuZwPYXQra5CmP41FUKI4cOHa61nVFSUEEK5plGLFi1EpUqVhJ2dnWjevLlYs2aNUCgUGseJiooSLVq0EJaWlqJOnToiPDy8/CtTiKLqKYQQCQkJolu3bsLGxkY4OjqKadOmiRcvXmgcRx/1lAlhAqP/iIiIiPRAkrO6iIiISJoY+BAREZFkMPAhIiIiyWDgQ0RERJLBwIeIiIgkg4EPERERSQYDHyIiIpIMBj5EREQkGQx8iEgvhBAYO3YsqlWrBplMhnPnzpXqeB06dMDmzZv1U7hyMnPmTEyaNMnQxSCiQjDwISK92L9/PzZs2IDdu3cjJSUFTZs2xe+//44ePXqgVq1akMlk+PXXX3U61q5du5CWloZ3331Xnebp6QmZTKbxcnNz09geGhpa4DETExMxatQo1KpVC5aWlvDw8MCUKVNw//59jXydOnVSH9/a2hqNGzfGqlWrdCr39OnTsXHjRty4cUOn/ERU/hj4EJFeXL9+HS4uLmjXrh2cnZ1RoUIFPH36FM2bN8fKlSuLdaxvvvkGI0eOzPdE7gULFiAlJUX9io2N1el4N27cQOvWrXH16lVs2bIF165dw5o1axAZGQk/Pz88ePBAI/+YMWOQkpKCy5cv45133sGECROwZcuWIs/j6OiIwMBArF69WvfKElG5YuBDRKU2YsQITJo0Cbdu3YJMJoOnpycAoFu3bvj888/Rp08fnY919+5dHDlyBD169Mi3rXLlynB2dla/atSoodMxJ0yYAEtLSxw8eBAdO3ZE7dq10a1bNxw+fBhJSUn45JNPNPLb2trC2dkZderUwbx581CvXj3s2rULALB9+3b4+PjAxsYG1atXR0BAAJ4+faret0ePHti6davO9SWi8sXAh4hKLSwsDAsWLICbmxtSUlLw559/lvhYx44dg62tLRo1aqSXsj148AAHDhzABx98ABsbG41tzs7OGDx4MLZt24bCntdsY2OD7OxspKSkYODAgRg1ahTi4uIQHR2NoKAgjX3btm2L27dvIyEhQS/lJyL9YuBDRKXm4OCAypUrQy6XF6slRpubN2/CyckpXzcXAHz88ceoVKmS+vXNN98UebyrV69CCFFgINWoUSM8fPgQd+/ezbdNoVDghx9+wPnz5/H6668jJSUFL1++RFBQEDw9PeHj44MPPvgAlSpVUu9Tq1YtdT2IyPhUMHQBiIhyy8zMhLW1tdZtM2bMwIgRI9TvHR0ddT5uYS06ea1atQrfffcdsrOzIZfL8eGHH+L999+HEAJdunSBj48PAgMD8eabb6Jfv36oWrWqel9Vq9KzZ890Ph8RlR+2+BCRUXF0dMTDhw8L3Obt7a1+ValSpcjjeXt7QyaTIS4uTuv2uLg4VK1aVaOVavDgwTh37hzi4+Px9OlTLFu2DBYWFpDL5Th06BD27duHxo0bY/ny5WjQoAHi4+PV+6oGSpem1YuIyg4DHyIyKi1btkRqamqBwU9xVa9eHW+88QZWrVqFzMxMjW2pqan48ccfMWDAAMhkMnW6g4MDvL294erqmq/LTSaToX379pg/fz5iY2NhaWmJHTt2qLdfvHgRFStWRJMmTfRSfiLSL3Z1EVGZefLkCa5du6Z+Hx8fj3PnzqFatWqoXbu21n1atmwJR0dHHD9+HG+//XaxzpeUlJRv4UQPDw+sWLEC7dq1Q2BgID7//HN4eXnh0qVLmDFjBlxdXfHFF1/odPyTJ08iMjISb775JmrWrImTJ0/i7t27GuOHjh49Cn9//3wDqYnIOLDFh4jKzOnTp9GyZUu0bNkSABAcHIyWLVtizpw5Be4jl8sxcuRI/Pjjj8U+31dffaU+n+q1Z88e1KtXD6dPn0adOnXwzjvvoG7duhg7diw6d+6MmJgYVKtWTafj29vb4/fff8dbb72F+vXrY/bs2Vi6dCm6deumzrN161aMGTOm2GUnovIhE8UZ8UdEVA5SU1PRpEkTnD17Fh4eHoYujs727duHadOm4fz586hQgQ3qRMaILT5EZHScnZ2xfv163Lp1y9BFKZanT58iPDycQQ+REWOLDxEREUkGW3yIiIhIMhj4EBERkWQw8CEiIiLJYOBDREREksHAh4iIiCSDgQ8RERFJBgMfIiIikgwGPkRERCQZDHyIiIhIMv4fZIOnm9mYzhwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitness Values (f1, f2):\n",
            "(-236.52314151702257, 0.9428311414132617)\n",
            "(-176.44661534546879, 0.07641685943805143)\n",
            "(-388.2529144261134, 0.9303188848378237)\n",
            "(-398.7766268796862, 0.7811704237869193)\n",
            "(-169.94712162851846, 0.4954521034609818)\n",
            "(-345.4604360606738, 0.45012443241975963)\n",
            "(-409.2141222538543, 0.8893909161288442)\n",
            "(-319.75213730809685, 0.8824594404560998)\n",
            "(-457.7226080374904, 0.9882752710001314)\n",
            "(-322.6907650225527, 0.04783082039410547)\n",
            "(-484.79126070501803, 0.7462072574818386)\n",
            "(-236.38578631852766, 0.8021305581275875)\n",
            "(-457.8529864188776, 0.03557086703554835)\n",
            "(-296.5682842209686, 0.38759523148276953)\n",
            "(-315.2212253316177, 0.991588408870274)\n",
            "(-111.70001693173191, 0.9423153896731928)\n",
            "(-186.46292929293048, 0.3548413602568904)\n",
            "(-335.14762789489134, 0.5496160437189245)\n",
            "(-167.78621743806406, 0.06871283251826776)\n",
            "(-330.28124564604474, 0.08261766345926869)\n",
            "(-294.13696537059536, 0.8989008240062354)\n",
            "(-187.00603017442484, 0.22784241754310997)\n",
            "(-109.603660160483, 0.6673503980464284)\n",
            "(-495.82892024103876, 0.2554134846852195)\n",
            "(-395.71468003203336, 0.06925430628585993)\n",
            "(-116.0693927696284, 0.47825529457592375)\n",
            "(-141.6741610512472, 0.32221550344462835)\n",
            "(-449.90657182686914, 0.4743361099062139)\n",
            "(-454.41734611427313, 0.4860155029775399)\n",
            "(-131.8811275122369, 0.5207681418342127)\n",
            "\n",
            "Pareto Front:\n",
            "(-457.8529864188776, 0.03557086703554835)\n",
            "(-495.82892024103876, 0.2554134846852195)\n"
          ]
        }
      ]
    }
  ]
}